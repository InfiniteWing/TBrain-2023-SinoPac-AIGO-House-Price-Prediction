{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c2cc25f-0323-45ae-9cdf-8c7d84eeff3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T18:48:59.525680Z",
     "iopub.status.busy": "2023-11-19T18:48:59.525389Z",
     "iopub.status.idle": "2023-11-19T18:49:00.480707Z",
     "shell.execute_reply": "2023-11-19T18:49:00.479861Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyproj\n",
    "from tqdm import tqdm\n",
    "import folium\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import random\n",
    "import haversine as hs\n",
    "from multiprocessing import Pool\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import neighbors\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b158b7a-bb6a-4a08-8dba-803aa0aee6c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T18:49:00.484008Z",
     "iopub.status.busy": "2023-11-19T18:49:00.483349Z",
     "iopub.status.idle": "2023-11-19T18:49:00.487716Z",
     "shell.execute_reply": "2023-11-19T18:49:00.486939Z"
    }
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50c6ef80-d2ba-45b5-a561-7627a42d94ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T18:49:00.489758Z",
     "iopub.status.busy": "2023-11-19T18:49:00.489614Z",
     "iopub.status.idle": "2023-11-19T18:49:00.595740Z",
     "shell.execute_reply": "2023-11-19T18:49:00.595109Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../官方資料集/training_data.csv')\n",
    "df_valid = pd.concat([pd.read_csv('../官方資料集/public_dataset.csv'), pd.read_csv('../官方資料集/private_dataset.csv')]).reset_index(drop=True)\n",
    "df_valid['單價'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25b81e1-8af6-44b7-99f2-98fd40872f59",
   "metadata": {},
   "source": [
    "### 官方原始欄位轉換，Rename columns and transform categorical cols with label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55707397-be51-40f4-971d-519f609b39af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T18:49:00.597766Z",
     "iopub.status.busy": "2023-11-19T18:49:00.597392Z",
     "iopub.status.idle": "2023-11-19T18:49:00.699796Z",
     "shell.execute_reply": "2023-11-19T18:49:00.699064Z"
    }
   },
   "outputs": [],
   "source": [
    "column_transforms_with_le = {\n",
    "    '建物型態': 'building_type',\n",
    "    '主要建材': 'main_material',\n",
    "    '主要用途': 'main_usage',\n",
    "    '縣市': 'city_1',\n",
    "    '鄉鎮市區': 'city_2',\n",
    "    '路名': 'city_3',\n",
    "    '使用分區': 'use_type'\n",
    "}\n",
    "\n",
    "for col, new_col in column_transforms_with_le.items():\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_train[col].values.tolist() + df_valid[col].values.tolist())\n",
    "    df_train[new_col] = le.transform(df_train[col].values.tolist())\n",
    "    df_valid[new_col] = le.transform(df_valid[col].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95441b26-7a5d-43d7-b8fe-724b4d453a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T18:49:00.701623Z",
     "iopub.status.busy": "2023-11-19T18:49:00.701417Z",
     "iopub.status.idle": "2023-11-19T18:49:00.709855Z",
     "shell.execute_reply": "2023-11-19T18:49:00.709163Z"
    }
   },
   "outputs": [],
   "source": [
    "column_transforms = {\n",
    "    '移轉層次': 'floor',\n",
    "    '總樓層數': 'total_floor',\n",
    "    '土地面積': 'ground_area',\n",
    "    '屋齡': 'age',\n",
    "    '建物面積': 'building_area',\n",
    "    '車位面積': 'car_area',\n",
    "    '車位個數': 'car_cnt',\n",
    "    '主建物面積': 'room_area',\n",
    "    '陽台面積': 'room_area_balcony',\n",
    "    '附屬建物面積': 'room_area_sub',\n",
    "    '單價': 'price'\n",
    "}\n",
    "for col, new_col in column_transforms.items():\n",
    "    df_train[new_col] = df_train[col].values\n",
    "    df_valid[new_col] = df_valid[col].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598aeae-abcd-4a22-8010-644744f795f9",
   "metadata": {},
   "source": [
    "### 座標系統轉換，TWD97 coordinate to WGS84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0856f498-e961-458a-a8a5-c4e55de81837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T18:49:00.712033Z",
     "iopub.status.busy": "2023-11-19T18:49:00.711888Z",
     "iopub.status.idle": "2023-11-19T18:49:34.642569Z",
     "shell.execute_reply": "2023-11-19T18:49:34.641766Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:16<00:00, 695.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:16<00:00, 714.63it/s]\n"
     ]
    }
   ],
   "source": [
    "twd97 = pyproj.Proj(init='epsg:3826')  # TWD97\n",
    "wgs84 = pyproj.Proj(init='epsg:4326')  # WGS84\n",
    "\n",
    "def get_coordinate(row):\n",
    "    lon, lat = pyproj.transform(twd97, wgs84, row['橫坐標'], row['縱坐標'])\n",
    "    return {\n",
    "        'ID': row['ID'],\n",
    "        'twd97_lon': lon,\n",
    "        'twd97_lat': lat\n",
    "    }\n",
    "\n",
    "with Pool(22) as pool:\n",
    "    features = list(tqdm(pool.imap(get_coordinate, df_train.to_dict('records')), total=len(df_train)))\n",
    "df_train_features = pd.DataFrame(features).fillna(-999999)\n",
    "with Pool(22) as pool:\n",
    "    features = list(tqdm(pool.imap(get_coordinate, df_valid.to_dict('records')), total=len(df_valid)))\n",
    "df_valid_features = pd.DataFrame(features).fillna(-999999)\n",
    "\n",
    "df_train = df_train.merge(df_train_features, how='left', on='ID')\n",
    "df_valid = df_valid.merge(df_valid_features, how='left', on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f93b55ef-1656-447d-a0d9-9b74dba048dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T18:49:34.644763Z",
     "iopub.status.busy": "2023-11-19T18:49:34.644430Z",
     "iopub.status.idle": "2023-11-19T18:49:34.720361Z",
     "shell.execute_reply": "2023-11-19T18:49:34.719224Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_datas = df_train.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f4cfcc9-b6bc-4b27-bd1e-6eebdb89d424",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T18:49:34.723102Z",
     "iopub.status.busy": "2023-11-19T18:49:34.722861Z",
     "iopub.status.idle": "2023-11-19T18:49:34.729471Z",
     "shell.execute_reply": "2023-11-19T18:49:34.728746Z"
    }
   },
   "outputs": [],
   "source": [
    "nearest_n = 100\n",
    "def get_distance_without_cache(lat1, lon1, lat2, lon2):\n",
    "    p1 = (lat1, lon1)\n",
    "    p2 = (lat2, lon2)\n",
    "    distance = hs.haversine(p1, p2, unit=hs.Unit.METERS)\n",
    "    return distance\n",
    "    \n",
    "def get_nearest_infos(id_ = 'id', n = 10, lat1 = 0, lon1 = 0):\n",
    "    results = []\n",
    "    for data in dict_datas:\n",
    "        if data['ID'] == id_:\n",
    "            continue\n",
    "        results.append({\n",
    "            'distance': get_distance_without_cache(lat1, lon1, data['twd97_lat'], data['twd97_lon']),\n",
    "            'price': data['price'],\n",
    "            'floor': data['floor'],\n",
    "            'age': data['age'],\n",
    "            'total_floor': data['total_floor']\n",
    "        })\n",
    "    results = sorted(results, key=lambda x: x[\"distance\"])\n",
    "    return results[:n]\n",
    "\n",
    "def get_feature(row):\n",
    "    global nearest_n\n",
    "    infos = get_nearest_infos(row['ID'], nearest_n, row['twd97_lat'], row['twd97_lon'])\n",
    "    tmp_df = pd.DataFrame(infos)\n",
    "    return {\n",
    "        'ID': row['ID'],\n",
    "        f'nearest_{nearest_n}_price_mean': tmp_df['price'].mean(),\n",
    "        f'nearest_{nearest_n}_price_median': tmp_df['price'].median(),\n",
    "        f'nearest_{nearest_n}_price_std': tmp_df['price'].std(),\n",
    "        f'nearest_{nearest_n}_price_max': tmp_df['price'].max(),\n",
    "        f'nearest_{nearest_n}_price_min': tmp_df['price'].min(),\n",
    "        \n",
    "        f'nearest_{nearest_n}_age_median': tmp_df['age'].median(),\n",
    "        f'nearest_{nearest_n}_age_std': tmp_df['age'].std(),\n",
    "        f'nearest_{nearest_n}_age_max': tmp_df['age'].max(),\n",
    "        f'nearest_{nearest_n}_age_min': tmp_df['age'].min(),\n",
    "\n",
    "        f'nearest_{nearest_n}_floor_median': tmp_df['floor'].median(),\n",
    "        f'nearest_{nearest_n}_total_floor_median': tmp_df['total_floor'].median()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d03d36e-5dda-4759-9f81-c8c138a76f8c",
   "metadata": {},
   "source": [
    "### 以距離產生每筆資料物理距離最近之4, 10, 30, 100筆資料之特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62d14aa7-7970-47ee-8f72-a7f962642fa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T18:49:34.731227Z",
     "iopub.status.busy": "2023-11-19T18:49:34.730991Z",
     "iopub.status.idle": "2023-11-19T18:52:47.329150Z",
     "shell.execute_reply": "2023-11-19T18:52:47.327815Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:23<00:00, 497.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:23<00:00, 495.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:24<00:00, 485.43it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:23<00:00, 501.06it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:23<00:00, 495.71it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:23<00:00, 490.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:23<00:00, 491.87it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:23<00:00, 497.42it/s]\n"
     ]
    }
   ],
   "source": [
    "for _nearest_n in [100, 30, 10, 4]:\n",
    "    global nearest_n\n",
    "    nearest_n = _nearest_n\n",
    "    with Pool(22) as pool:\n",
    "        features = list(tqdm(pool.imap(get_feature, df_train.to_dict('records')), total=len(df_train)))\n",
    "    df_train_features = pd.DataFrame(features)\n",
    "    with Pool(22) as pool:\n",
    "        features = list(tqdm(pool.imap(get_feature, df_valid.to_dict('records')), total=len(df_valid)))\n",
    "    df_valid_features = pd.DataFrame(features)\n",
    "    \n",
    "    df_train = df_train.merge(df_train_features, how='left', on='ID')\n",
    "    df_valid = df_valid.merge(df_valid_features, how='left', on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9080b66-b906-4d9b-a873-3f1ddbdc5ffa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T18:52:47.332311Z",
     "iopub.status.busy": "2023-11-19T18:52:47.331985Z",
     "iopub.status.idle": "2023-11-19T18:52:47.338619Z",
     "shell.execute_reply": "2023-11-19T18:52:47.337842Z"
    }
   },
   "outputs": [],
   "source": [
    "distance_threshold = 3600\n",
    "def get_ref_infos(id_ = 'id', distance_threshold = 1000, lat1 = 0, lon1 = 0):\n",
    "    results = []\n",
    "    for data in dict_datas:\n",
    "        if data['ID'] == id_:\n",
    "            continue\n",
    "        distance = get_distance_without_cache(lat1, lon1, data['twd97_lat'], data['twd97_lon'])\n",
    "        if distance <= distance_threshold:\n",
    "            results.append({\n",
    "                'distance': distance,\n",
    "                'price': data['price'],\n",
    "                'floor': data['floor'],\n",
    "                'age': data['age'],\n",
    "                'total_floor': data['total_floor']\n",
    "            })\n",
    "    return results\n",
    "\n",
    "def get_ref_feature(row):\n",
    "    global distance_threshold\n",
    "    infos = get_ref_infos(row['ID'], distance_threshold, row['twd97_lat'], row['twd97_lon'])\n",
    "    tmp_df = pd.DataFrame(infos)\n",
    "    if len(tmp_df) == 0:\n",
    "        return {}\n",
    "    return {\n",
    "        'ID': row['ID'],\n",
    "        f'ref_{distance_threshold}_price_mean': tmp_df['price'].mean(),\n",
    "        f'ref_{distance_threshold}_price_median': tmp_df['price'].median(),\n",
    "        f'ref_{distance_threshold}_price_std': tmp_df['price'].std(),\n",
    "        f'ref_{distance_threshold}_price_max': tmp_df['price'].max(),\n",
    "        f'ref_{distance_threshold}_price_min': tmp_df['price'].min(),\n",
    "        \n",
    "        f'ref_{distance_threshold}_age_median': tmp_df['age'].median(),\n",
    "        f'ref_{distance_threshold}_age_std': tmp_df['age'].std(),\n",
    "        f'ref_{distance_threshold}_age_max': tmp_df['age'].max(),\n",
    "        f'ref_{distance_threshold}_age_min': tmp_df['age'].min(),\n",
    "        \n",
    "        f'ref_{distance_threshold}_floor_median': tmp_df['floor'].median(),\n",
    "        f'ref_{distance_threshold}_total_floor_median': tmp_df['total_floor'].median()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbb1b3f-5b1b-49d4-98b6-f822f237cf82",
   "metadata": {},
   "source": [
    "### 以距離產生每筆資料物理距離500, 1200, 3600公尺內資料之特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d2798d6-582a-49a1-bdc5-2b78793300fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T18:52:47.340264Z",
     "iopub.status.busy": "2023-11-19T18:52:47.340030Z",
     "iopub.status.idle": "2023-11-19T18:54:11.424526Z",
     "shell.execute_reply": "2023-11-19T18:54:11.423358Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:14<00:00, 836.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:14<00:00, 837.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:13<00:00, 871.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:13<00:00, 871.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:13<00:00, 876.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:13<00:00, 878.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for _distance_threshold in [3600, 1200, 500]:\n",
    "    global distance_threshold\n",
    "    distance_threshold = _distance_threshold\n",
    "    with Pool(22) as pool:\n",
    "        features = list(tqdm(pool.imap(get_ref_feature, df_train.to_dict('records')), total=len(df_train)))\n",
    "    df_train_features = pd.DataFrame(features)\n",
    "    with Pool(22) as pool:\n",
    "        features = list(tqdm(pool.imap(get_ref_feature, df_valid.to_dict('records')), total=len(df_valid)))\n",
    "    df_valid_features = pd.DataFrame(features)\n",
    "    \n",
    "    df_train = df_train.merge(df_train_features, how='left', on='ID')\n",
    "    df_valid = df_valid.merge(df_valid_features, how='left', on='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a492e-13af-4949-b8f4-7e0c4ef8a850",
   "metadata": {},
   "source": [
    "### 整合外部資料集，包含官方給予的外部資料集，以及我蒐集的外部資料集(警察局、消防局、加油站位置資訊)\n",
    "### 以距離產生每筆資料物理距離200, 500, 1200, 3600公尺內外部資料集之counting特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73dbca19-3d08-4193-9499-0c2894dfd5e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T18:54:11.427551Z",
     "iopub.status.busy": "2023-11-19T18:54:11.427294Z",
     "iopub.status.idle": "2023-11-19T18:54:11.914847Z",
     "shell.execute_reply": "2023-11-19T18:54:11.913713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extra_info_atm', 'fire_department', 'gas_staion', 'police_office', 'extra_info_c_store', 'extra_info_bus_stop', 'extra_info_lv2_school', 'extra_info_lv1_school', 'extra_info_lv4_school', 'extra_info_mrt_station', 'extra_info_train_station', 'extra_info_bike_station', 'extra_info_post_office', 'extra_info_hospital', 'extra_info_bank', 'extra_info_lv3_school']\n"
     ]
    }
   ],
   "source": [
    "extra_info_name_maps = {\n",
    "    '便利商店': 'extra_info_c_store',\n",
    "    'ATM資料': 'extra_info_atm',\n",
    "    '公車站點資料': 'extra_info_bus_stop',\n",
    "    '國小基本資料': 'extra_info_lv1_school',\n",
    "    '國中基本資料': 'extra_info_lv2_school',\n",
    "    '高中基本資料': 'extra_info_lv3_school',\n",
    "    '大學基本資料': 'extra_info_lv4_school',\n",
    "    '捷運站點資料': 'extra_info_mrt_station',\n",
    "    '火車站點資料': 'extra_info_train_station',\n",
    "    '腳踏車站點資料': 'extra_info_bike_station',\n",
    "    '郵局據點資料': 'extra_info_post_office',\n",
    "    '醫療機構基本資料': 'extra_info_hospital',\n",
    "    '金融機構基本資料': 'extra_info_bank',\n",
    "}\n",
    "extra_infos = {}\n",
    "for pathto_train in glob.glob('../官方資料集/external_data/*.csv'):\n",
    "    #print(pathto_train)\n",
    "    df_extra = pd.read_csv(pathto_train)\n",
    "    info_name = pathto_train.split('/')[-1].split('.')[0]\n",
    "    if info_name in extra_info_name_maps:\n",
    "        info_name = extra_info_name_maps[info_name]\n",
    "    if 'lon' not in df_extra.columns:\n",
    "        df_extra['lon'] = df_extra['lng'].values\n",
    "    extra_use_cols = ['lon', 'lat']\n",
    "    extra_infos[info_name] = df_extra[extra_use_cols].to_dict('records')\n",
    "print(list(extra_infos.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a17c0149-2c01-4a10-916d-d358feec6b6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T18:54:11.917645Z",
     "iopub.status.busy": "2023-11-19T18:54:11.917297Z",
     "iopub.status.idle": "2023-11-19T18:54:11.922094Z",
     "shell.execute_reply": "2023-11-19T18:54:11.921483Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_extra_infos(distance_threshold, lat1, lon1):\n",
    "    infos = {}\n",
    "    for extra_info_name in extra_infos.keys():\n",
    "        cnt = 0\n",
    "        for data in extra_infos[extra_info_name]:\n",
    "            distance = get_distance_without_cache(lat1, lon1, data['lat'], data['lon'])\n",
    "            if distance <= distance_threshold:\n",
    "                cnt += 1\n",
    "        infos.update({f'{extra_info_name}_{distance_threshold}_cnt': cnt})\n",
    "    return infos\n",
    "\n",
    "def get_extra_feature(row):\n",
    "    features = {}\n",
    "    features.update(get_extra_infos(200, row['twd97_lat'], row['twd97_lon']))\n",
    "    features.update(get_extra_infos(500, row['twd97_lat'], row['twd97_lon']))\n",
    "    features.update(get_extra_infos(1200, row['twd97_lat'], row['twd97_lon']))\n",
    "    features.update(get_extra_infos(3600, row['twd97_lat'], row['twd97_lon']))\n",
    "    features.update({'ID': row['ID']})\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2491ea5-0099-40b3-99d1-88b693f67715",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T18:54:11.923717Z",
     "iopub.status.busy": "2023-11-19T18:54:11.923557Z",
     "iopub.status.idle": "2023-11-19T19:17:31.059020Z",
     "shell.execute_reply": "2023-11-19T19:17:31.058281Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [11:38<00:00, 16.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [11:39<00:00, 16.81it/s]\n"
     ]
    }
   ],
   "source": [
    "with Pool(22) as pool:\n",
    "    features = list(tqdm(pool.imap(get_extra_feature, df_train.to_dict('records')), total=len(df_train)))\n",
    "df_train_extra_features = pd.DataFrame(features)\n",
    "\n",
    "with Pool(22) as pool:\n",
    "    features = list(tqdm(pool.imap(get_extra_feature, df_valid.to_dict('records')), total=len(df_valid)))\n",
    "df_valid_extra_features = pd.DataFrame(features)\n",
    "\n",
    "df_train = df_train.merge(df_train_extra_features, how='left', on='ID')\n",
    "df_valid = df_valid.merge(df_valid_extra_features, how='left', on='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470a3d0d-c569-436f-9d81-068eccb75817",
   "metadata": {},
   "source": [
    "### 製作面積相關額外特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "544f9a9c-76e5-4757-9b2c-249b08a6c484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:17:31.062374Z",
     "iopub.status.busy": "2023-11-19T19:17:31.061986Z",
     "iopub.status.idle": "2023-11-19T19:17:31.087594Z",
     "shell.execute_reply": "2023-11-19T19:17:31.086964Z"
    }
   },
   "outputs": [],
   "source": [
    "area_cols = [c for c in df_train.columns if 'area' in c]\n",
    "for area_col1 in area_cols:\n",
    "    for area_col2 in area_cols:\n",
    "        if area_col1 == area_col2:\n",
    "            continue\n",
    "        df_train[f'{area_col1}_add_{area_col2}'] = df_train[area_col1] + df_train[area_col2]\n",
    "        df_valid[f'{area_col1}_add_{area_col2}'] = df_valid[area_col1] + df_valid[area_col2]\n",
    "        df_train[f'{area_col1}_minus_{area_col2}'] = df_train[area_col1] - df_train[area_col2]\n",
    "        df_valid[f'{area_col1}_minus_{area_col2}'] = df_valid[area_col1] - df_valid[area_col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add33110-ade9-4b6b-bb4d-b432ac1911cb",
   "metadata": {},
   "source": [
    "### 製作縣市、鄉鎮市區統計特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b233733f-78f6-4c09-9b73-690841684d95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:17:31.089492Z",
     "iopub.status.busy": "2023-11-19T19:17:31.089260Z",
     "iopub.status.idle": "2023-11-19T19:17:31.138953Z",
     "shell.execute_reply": "2023-11-19T19:17:31.138124Z"
    }
   },
   "outputs": [],
   "source": [
    "city12_df = df_train.groupby(['city_1', 'city_2'])['price'].agg(['mean', 'std', 'max', 'min']).reset_index().rename(columns = {\n",
    "    'mean': 'city12_price_mean',\n",
    "    'std': 'city12_price_std',\n",
    "    'max': 'city12_price_max',\n",
    "    'min': 'city12_price_min',\n",
    "})\n",
    "df_train = df_train.merge(city12_df, how='left', on=['city_1', 'city_2']).fillna(-99999)\n",
    "df_valid = df_valid.merge(city12_df, how='left', on=['city_1', 'city_2']).fillna(-99999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "996df75e-9a1a-400e-a2a8-43efbecc96eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:17:31.142409Z",
     "iopub.status.busy": "2023-11-19T19:17:31.142208Z",
     "iopub.status.idle": "2023-11-19T19:17:31.146823Z",
     "shell.execute_reply": "2023-11-19T19:17:31.146026Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['floor_from_top'] = df_train['total_floor'] - df_train['floor']\n",
    "df_valid['floor_from_top'] = df_valid['total_floor'] - df_valid['floor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0a3cb83-e507-4660-865f-ad21597425a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:17:31.150234Z",
     "iopub.status.busy": "2023-11-19T19:17:31.150070Z",
     "iopub.status.idle": "2023-11-19T19:17:31.180310Z",
     "shell.execute_reply": "2023-11-19T19:17:31.179739Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['city12'] = df_train['city_1'].astype(str) + '_' + df_train['city_2'].astype(str)\n",
    "df_valid['city12'] = df_valid['city_1'].astype(str) + '_' + df_valid['city_2'].astype(str)\n",
    "col = 'city12'\n",
    "new_col = 'city12'\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train[col].values.tolist() + df_valid[col].values.tolist())\n",
    "df_train[new_col] = le.transform(df_train[col].values.tolist())\n",
    "df_valid[new_col] = le.transform(df_valid[col].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840a9dbe-ec4b-4bfc-9916-933842158848",
   "metadata": {},
   "source": [
    "### 製作實價登錄相關特徵，會用不同的方式mapping原始資料以及實價登錄資料，詳見下方的key欄位生成方式與對應程式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309ecd2-aadd-4242-94e9-3ed77ff45086",
   "metadata": {},
   "source": [
    "### 製作實價登錄不動產實際成交之特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58805b4f-f12f-4485-8688-51d5c18c13db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:17:31.183411Z",
     "iopub.status.busy": "2023-11-19T19:17:31.183235Z",
     "iopub.status.idle": "2023-11-19T19:17:32.280419Z",
     "shell.execute_reply": "2023-11-19T19:17:32.279702Z"
    }
   },
   "outputs": [],
   "source": [
    "df_external_gov_data = pd.read_csv('../外部資料集/實價登錄/external_gov_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75fd8e87-0dc6-4c69-806c-1e26be4b3081",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:17:32.282656Z",
     "iopub.status.busy": "2023-11-19T19:17:32.282519Z",
     "iopub.status.idle": "2023-11-19T19:17:32.292552Z",
     "shell.execute_reply": "2023-11-19T19:17:32.291771Z"
    }
   },
   "outputs": [],
   "source": [
    "externalkey2subdf = {}\n",
    "key_col = 'key'\n",
    "_new_col_name = ''\n",
    "_age_in = None\n",
    "\n",
    "def get_external_feature(row):\n",
    "    global _new_col_name, _age_in\n",
    "    if row[key_col] not in externalkey2subdf:\n",
    "        return {}\n",
    "    subdf = externalkey2subdf[row[key_col]]\n",
    "    if len(subdf) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        if _age_in != None:\n",
    "            subdf['age_diff'] = np.abs(row['屋齡'] - subdf['屋齡'])\n",
    "            subdf = subdf.query(f'age_diff <= {_age_in}')\n",
    "        return {\n",
    "            'ID': row['ID'],\n",
    "            f'{_new_col_name}_price_mean': subdf['單價'].mean(),\n",
    "            f'{_new_col_name}_price_std': subdf['單價'].std(),\n",
    "            f'{_new_col_name}_price_max': subdf['單價'].max(),\n",
    "            f'{_new_col_name}_price_min': subdf['單價'].min(),\n",
    "            f'{_new_col_name}_price_max_min_ratio': (subdf['單價'].max()-subdf['單價'].min()) / subdf['單價'].mean(),\n",
    "            f'{_new_col_name}_price_cnt': len(subdf),\n",
    "\n",
    "            f'{_new_col_name}_price_sameroad_50ma_mean': subdf['單價_同路_50MA'].mean(),\n",
    "            f'{_new_col_name}_price_sameroad_100ma_mean': subdf['單價_同路_100MA'].mean(),\n",
    "            f'{_new_col_name}_price_sameroad_200ma_mean': subdf['單價_同路_200MA'].mean(),\n",
    "            f'{_new_col_name}_price_sameroad_50ma_std_mean': subdf['單價_同路_50MA_STD'].mean(),\n",
    "            f'{_new_col_name}_price_sameroad_100ma_std_mean': subdf['單價_同路_100MA_STD'].mean(),\n",
    "            f'{_new_col_name}_price_sameroad_200ma_std_mean': subdf['單價_同路_200MA_STD'].mean(),\n",
    "            \n",
    "            f'{_new_col_name}_price_samecity12_50ma_mean': subdf['單價_同鄉鎮市區_50MA'].mean(),\n",
    "            f'{_new_col_name}_price_samecity12_100ma_mean': subdf['單價_同鄉鎮市區_100MA'].mean(),\n",
    "            f'{_new_col_name}_price_samecity12_200ma_mean': subdf['單價_同鄉鎮市區_200MA'].mean(),\n",
    "            f'{_new_col_name}_price_samecity12_50ma_std_mean': subdf['單價_同鄉鎮市區_50MA_STD'].mean(),\n",
    "            f'{_new_col_name}_price_samecity12_100ma_std_mean': subdf['單價_同鄉鎮市區_100MA_STD'].mean(),\n",
    "            f'{_new_col_name}_price_samecity12_200ma_std_mean': subdf['單價_同鄉鎮市區_200MA_STD'].mean(),\n",
    "            \n",
    "            f'{_new_col_name}_land1_mean': subdf['土地面積'].mean(),\n",
    "            f'{_new_col_name}_land2_mean': subdf['建物面積'].mean(),\n",
    "            f'{_new_col_name}_land3_mean': subdf['車位面積'].mean(),\n",
    "            f'{_new_col_name}_land4_mean': subdf['主建物面積'].mean(),\n",
    "            f'{_new_col_name}_land5_mean': subdf['陽台面積'].mean(),\n",
    "            f'{_new_col_name}_land6_mean': subdf['附屬建物面積'].mean(),\n",
    "\n",
    "            f'{_new_col_name}_age_diff_mean': subdf['屋齡'].mean() - row['屋齡'],\n",
    "        }\n",
    "        \n",
    "def mapping_external_gov_data(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by, \n",
    "    new_col_name,\n",
    "    age_in = None,):\n",
    "    \n",
    "    global _new_col_name, _age_in\n",
    "    _new_col_name = new_col_name\n",
    "    _age_in = age_in\n",
    "    \n",
    "    df_train[key_col] = df_train[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "    df_valid[key_col] = df_valid[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "    df_external_gov_data[key_col] = df_external_gov_data[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_train[key_col].values.tolist() + df_valid[key_col].values.tolist() + df_external_gov_data[key_col].values.tolist())\n",
    "    df_train[key_col] = le.transform(df_train[key_col].values.tolist())\n",
    "    df_valid[key_col] = le.transform(df_valid[key_col].values.tolist())\n",
    "    df_external_gov_data[key_col] = le.transform(df_external_gov_data[key_col].values.tolist())\n",
    "\n",
    "\n",
    "    \n",
    "    global externalkey2subdf\n",
    "    externalkey2subdf = {}\n",
    "    for key, subdf in df_external_gov_data.groupby(key_col):\n",
    "        externalkey2subdf[key] = subdf\n",
    "    \n",
    "    with Pool(22) as pool:\n",
    "        features = list(tqdm(pool.imap(get_external_feature, df_train.to_dict('records')), total=len(df_train)))\n",
    "    df_train_features = pd.DataFrame(features)\n",
    "    df_train = df_train.merge(df_train_features, how='left', on='ID')\n",
    "    \n",
    "    with Pool(22) as pool:\n",
    "        features = list(tqdm(pool.imap(get_external_feature, df_valid.to_dict('records')), total=len(df_valid)))\n",
    "    df_valid_features = pd.DataFrame(features)\n",
    "    df_valid = df_valid.merge(df_valid_features, how='left', on='ID')\n",
    "    return df_train, df_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dca30f-2f12-4079-ada4-7ff99cfe5052",
   "metadata": {},
   "source": [
    "#### 以 縣市+鄉鎮市區+路名+主要用途+建物型態 對應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b867fd57-441c-4b9d-8dfe-7907700e34f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:17:32.295258Z",
     "iopub.status.busy": "2023-11-19T19:17:32.294994Z",
     "iopub.status.idle": "2023-11-19T19:17:41.971070Z",
     "shell.execute_reply": "2023-11-19T19:17:41.970058Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 3216.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 3693.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 91.099%, corr = 0.92604\n"
     ]
    }
   ],
   "source": [
    "new_col_name = 'externalkey'\n",
    "df_train, df_valid = mapping_external_gov_data(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by = ['縣市', '鄉鎮市區', '路名', '主要用途', '建物型態'], \n",
    "    new_col_name = new_col_name\n",
    ")\n",
    "na_cnt = sum(df_train[f'{new_col_name}_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'{new_col_name}_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0960ab-162e-4a1f-bdbe-61ae2a20630b",
   "metadata": {},
   "source": [
    "#### 以 縣市+鄉鎮市區+路名+主要用途+建物型態+總樓層數 對應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "369a3359-5d80-4eeb-b9de-b32f914b7037",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:17:41.974074Z",
     "iopub.status.busy": "2023-11-19T19:17:41.973265Z",
     "iopub.status.idle": "2023-11-19T19:17:50.757690Z",
     "shell.execute_reply": "2023-11-19T19:17:50.756992Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:02<00:00, 4526.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:02<00:00, 4684.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 87.584%, corr = 0.94854\n"
     ]
    }
   ],
   "source": [
    "new_col_name = 'externalkey_samebuilding'\n",
    "df_train, df_valid = mapping_external_gov_data(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by = ['縣市', '鄉鎮市區', '路名', '主要用途', '建物型態', '總樓層數'], \n",
    "    new_col_name = new_col_name\n",
    ")\n",
    "na_cnt = sum(df_train[f'{new_col_name}_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'{new_col_name}_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29996e7e-c356-459b-b907-722e91bec730",
   "metadata": {},
   "source": [
    "#### 以 縣市+鄉鎮市區+路名+主要用途+建物型態+總樓層數+移轉層次 對應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7131103d-a6f1-466b-b603-423888b514ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:17:50.759761Z",
     "iopub.status.busy": "2023-11-19T19:17:50.759521Z",
     "iopub.status.idle": "2023-11-19T19:18:01.969110Z",
     "shell.execute_reply": "2023-11-19T19:18:01.968111Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:02<00:00, 4866.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:02<00:00, 4791.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 66.505%, corr = 0.93587\n"
     ]
    }
   ],
   "source": [
    "new_col_name = 'externalkey_samefloor'\n",
    "df_train, df_valid = mapping_external_gov_data(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by = ['縣市', '鄉鎮市區', '路名', '主要用途', '建物型態', '總樓層數', '移轉層次'], \n",
    "    new_col_name = new_col_name\n",
    ")\n",
    "na_cnt = sum(df_train[f'{new_col_name}_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'{new_col_name}_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92115c8-737a-4efb-a39f-ca0bcb2db182",
   "metadata": {},
   "source": [
    "#### 以 縣市+鄉鎮市區+路名+主要用途+建物型態+總樓層數+移轉層次+車位個數 對應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a58cc2a4-46d9-4508-aecc-0dd69e8d3149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:18:01.972047Z",
     "iopub.status.busy": "2023-11-19T19:18:01.971513Z",
     "iopub.status.idle": "2023-11-19T19:18:01.978265Z",
     "shell.execute_reply": "2023-11-19T19:18:01.977635Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['車位個數'] = df_train['車位個數'].astype(int)\n",
    "df_valid['車位個數'] = df_valid['車位個數'].astype(int)\n",
    "df_external_gov_data['車位個數'] = df_external_gov_data['車位個數'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9255ab37-f505-4138-88d4-70e74a90336e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:18:01.980478Z",
     "iopub.status.busy": "2023-11-19T19:18:01.979930Z",
     "iopub.status.idle": "2023-11-19T19:18:17.769343Z",
     "shell.execute_reply": "2023-11-19T19:18:17.768289Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:05<00:00, 2341.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 3512.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 59.723%, corr = 0.94153\n"
     ]
    }
   ],
   "source": [
    "new_col_name = 'externalkey_samefloor_samecar'\n",
    "df_train, df_valid = mapping_external_gov_data(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by = ['縣市', '鄉鎮市區', '路名', '主要用途', '建物型態', '總樓層數', '移轉層次', '車位個數'], \n",
    "    new_col_name = new_col_name\n",
    ")\n",
    "na_cnt = sum(df_train[f'{new_col_name}_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'{new_col_name}_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcddae1-5894-4583-a028-2e3de3578adc",
   "metadata": {},
   "source": [
    "#### 以 縣市+鄉鎮市區+路名+主要用途+建物型態+屋齡(差距絕對值小於1年) 對應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a1143c2-458d-419b-801e-40f6d2fac641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:18:17.772401Z",
     "iopub.status.busy": "2023-11-19T19:18:17.771931Z",
     "iopub.status.idle": "2023-11-19T19:18:32.212664Z",
     "shell.execute_reply": "2023-11-19T19:18:32.211914Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:05<00:00, 2190.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:05<00:00, 2314.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 84.835%, corr = 0.95278\n"
     ]
    }
   ],
   "source": [
    "new_col_name = 'externalkey_sameage'\n",
    "df_train, df_valid = mapping_external_gov_data(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by = ['縣市', '鄉鎮市區', '路名', '主要用途', '建物型態'], \n",
    "    new_col_name = new_col_name,\n",
    "    age_in = 1.0\n",
    ")\n",
    "na_cnt = sum(df_train[f'{new_col_name}_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'{new_col_name}_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab5fc4-24fb-4a0e-ac33-d0d91c360ada",
   "metadata": {},
   "source": [
    "#### 以 縣市+鄉鎮市區+路名+主要用途+建物型態+屋齡(差距絕對值小於0.5年) 對應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49fdb2a8-c0ca-4f68-9893-a61b984bad89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:18:32.214959Z",
     "iopub.status.busy": "2023-11-19T19:18:32.214584Z",
     "iopub.status.idle": "2023-11-19T19:18:46.282726Z",
     "shell.execute_reply": "2023-11-19T19:18:46.281755Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:05<00:00, 2311.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:04<00:00, 2386.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 80.793%, corr = 0.95126\n"
     ]
    }
   ],
   "source": [
    "new_col_name = 'externalkey_sameage_05'\n",
    "df_train, df_valid = mapping_external_gov_data(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by = ['縣市', '鄉鎮市區', '路名', '主要用途', '建物型態'], \n",
    "    new_col_name = new_col_name,\n",
    "    age_in = 0.5\n",
    ")\n",
    "na_cnt = sum(df_train[f'{new_col_name}_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'{new_col_name}_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3708592-2eef-454d-9955-1c52fd61fdf4",
   "metadata": {},
   "source": [
    "#### 以 縣市+鄉鎮市區+路名+主要用途+建物型態+屋齡(差距絕對值小於0.25年) 對應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86df1820-ce2c-4a46-a14b-7a0cae073923",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:18:46.285365Z",
     "iopub.status.busy": "2023-11-19T19:18:46.285065Z",
     "iopub.status.idle": "2023-11-19T19:18:59.089786Z",
     "shell.execute_reply": "2023-11-19T19:18:59.088825Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:04<00:00, 2690.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:04<00:00, 2675.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 74.811%, corr = 0.94994\n"
     ]
    }
   ],
   "source": [
    "new_col_name = 'externalkey_sameage_0.25'\n",
    "df_train, df_valid = mapping_external_gov_data(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by = ['縣市', '鄉鎮市區', '路名', '主要用途', '建物型態'], \n",
    "    new_col_name = new_col_name,\n",
    "    age_in = 0.25\n",
    ")\n",
    "na_cnt = sum(df_train[f'{new_col_name}_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'{new_col_name}_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096f8fe7-0d1d-4b68-90bf-e4d4fef12df8",
   "metadata": {},
   "source": [
    "#### 以 縣市+鄉鎮市區+路名+主要用途+建物型態+屋齡(差距小於0.1年)+車位個數+總樓層數+移轉層次+**附屬建物面積** 對應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75ea221c-b6ad-4eb7-9576-6dbbe7782746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:18:59.092286Z",
     "iopub.status.busy": "2023-11-19T19:18:59.092036Z",
     "iopub.status.idle": "2023-11-19T19:19:16.561598Z",
     "shell.execute_reply": "2023-11-19T19:19:16.560900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:04<00:00, 2487.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:04<00:00, 2616.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 32.346%, corr = 0.95248\n"
     ]
    }
   ],
   "source": [
    "key_col = 'key'\n",
    "by = ['縣市', '鄉鎮市區', '路名', '主要用途', '建物型態', '總樓層數', '移轉層次', '車位個數']\n",
    "\n",
    "df_train[key_col] = df_train[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "df_valid[key_col] = df_valid[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "df_external_gov_data[key_col] = df_external_gov_data[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train[key_col].values.tolist() + df_valid[key_col].values.tolist() + df_external_gov_data[key_col].values.tolist())\n",
    "df_train[key_col] = le.transform(df_train[key_col].values.tolist())\n",
    "df_valid[key_col] = le.transform(df_valid[key_col].values.tolist())\n",
    "df_external_gov_data[key_col] = le.transform(df_external_gov_data[key_col].values.tolist())\n",
    "\n",
    "sub_area_0_external = df_external_gov_data['附屬建物面積'].value_counts().head(1).index[0]\n",
    "sub_area_0_train = df_train['附屬建物面積'].value_counts().head(1).index[0]\n",
    "\n",
    "# external datas \n",
    "externalkey2subdf = {}\n",
    "for key, subdf in df_external_gov_data.groupby(key_col):\n",
    "    externalkey2subdf[key] = subdf\n",
    "\n",
    "def get_external_same_building_feature(row):\n",
    "    if row[key_col] not in externalkey2subdf:\n",
    "        return {}\n",
    "    subdf = externalkey2subdf[row[key_col]]\n",
    "    if len(subdf) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        subdf['age_diff'] = row['屋齡']  - subdf['屋齡']\n",
    "        subdf2 = subdf.query('age_diff <= 0.1 and age_diff >= 0')\n",
    "        if np.abs(row['附屬建物面積'] - sub_area_0_train) <= 0.0001:\n",
    "            subdf2 = subdf2.query(f'附屬建物面積 <= {sub_area_0_external}')\n",
    "        else:\n",
    "            subdf2 = subdf2.query(f'附屬建物面積 > {sub_area_0_external}')\n",
    "        return {\n",
    "            'ID': row['ID'],\n",
    "            'externalkey_exactly_same_price_mean': subdf2['單價'].mean(),\n",
    "            #'externalkey_exactly_same_price_std': subdf2['單價'].std(),\n",
    "            'externalkey_exactly_same_price_max': subdf2['單價'].max(),\n",
    "            'externalkey_exactly_same_price_min': subdf2['單價'].min(),\n",
    "            'externalkey_exactly_same_price_max_min_ratio': (subdf2['單價'].max()-subdf2['單價'].min()) / subdf2['單價'].mean(),\n",
    "        }\n",
    "\n",
    "with Pool(22) as pool:\n",
    "    features = list(tqdm(pool.imap(get_external_same_building_feature, df_train.to_dict('records')), total=len(df_train)))\n",
    "df_train_features = pd.DataFrame(features)\n",
    "df_train = df_train.merge(df_train_features, how='left', on='ID')\n",
    "\n",
    "with Pool(22) as pool:\n",
    "    features = list(tqdm(pool.imap(get_external_same_building_feature, df_valid.to_dict('records')), total=len(df_valid)))\n",
    "df_valid_features = pd.DataFrame(features)\n",
    "df_valid = df_valid.merge(df_valid_features, how='left', on='ID')\n",
    "\n",
    "na_cnt = sum(df_train[f'externalkey_exactly_same_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'externalkey_exactly_same_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3996f87c-3047-468e-a3ac-6905f53a6291",
   "metadata": {},
   "source": [
    "### 基於 縣市+鄉鎮市區+路名+主要用途+建物型態 對應產生2021Q2 - 2022Q4每一季度的均價特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcd89c13-0f23-4460-b4d9-dfdc76e1fc73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:19:16.564514Z",
     "iopub.status.busy": "2023-11-19T19:19:16.564074Z",
     "iopub.status.idle": "2023-11-19T19:19:30.650390Z",
     "shell.execute_reply": "2023-11-19T19:19:30.649439Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:05<00:00, 2260.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:04<00:00, 2443.96it/s]\n"
     ]
    }
   ],
   "source": [
    "df_external_gov_data = pd.read_csv('../外部資料集/實價登錄/external_gov_data_by_year.csv')\n",
    "\n",
    "key_col = 'key'\n",
    "by = ['縣市', '鄉鎮市區', '路名', '主要用途', '建物型態']\n",
    "\n",
    "df_train[key_col] = df_train[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "df_valid[key_col] = df_valid[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "df_external_gov_data[key_col] = df_external_gov_data[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train[key_col].values.tolist() + df_valid[key_col].values.tolist() + df_external_gov_data[key_col].values.tolist())\n",
    "df_train[key_col] = le.transform(df_train[key_col].values.tolist())\n",
    "df_valid[key_col] = le.transform(df_valid[key_col].values.tolist())\n",
    "df_external_gov_data[key_col] = le.transform(df_external_gov_data[key_col].values.tolist())\n",
    "\n",
    "# external datas \n",
    "externalkey2subdf = {}\n",
    "for key, subdf in df_external_gov_data.groupby('key'):\n",
    "    externalkey2subdf[key] = subdf\n",
    "\n",
    "def get_external_same_building_feature(row):\n",
    "    if row['key'] not in externalkey2subdf:\n",
    "        return {}\n",
    "    subdf = externalkey2subdf[row['key']]\n",
    "    if len(subdf) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        return {\n",
    "            'ID': row['ID'],\n",
    "            'externalkey_year_21q2_price_mean': subdf.query('Trade_YearQ == 20211')['單價'].mean(),\n",
    "            'externalkey_year_21q3_price_mean': subdf.query('Trade_YearQ == 20212')['單價'].mean(),\n",
    "            'externalkey_year_21q4_price_mean': subdf.query('Trade_YearQ == 20213')['單價'].mean(),\n",
    "            \n",
    "            'externalkey_year_22q1_price_mean': subdf.query('Trade_YearQ == 20220')['單價'].mean(),\n",
    "            'externalkey_year_22q2_price_mean': subdf.query('Trade_YearQ == 20221')['單價'].mean(),\n",
    "            'externalkey_year_22q3_price_mean': subdf.query('Trade_YearQ == 20222')['單價'].mean(),\n",
    "            'externalkey_year_22q4_price_mean': subdf.query('Trade_YearQ == 20223')['單價'].mean(),\n",
    "        }\n",
    "\n",
    "with Pool(22) as pool:\n",
    "    features = list(tqdm(pool.imap(get_external_same_building_feature, df_train.to_dict('records')), total=len(df_train)))\n",
    "df_train_features = pd.DataFrame(features)\n",
    "df_train = df_train.merge(df_train_features, how='left', on='ID')\n",
    "\n",
    "with Pool(22) as pool:\n",
    "    features = list(tqdm(pool.imap(get_external_same_building_feature, df_valid.to_dict('records')), total=len(df_valid)))\n",
    "df_valid_features = pd.DataFrame(features)\n",
    "df_valid = df_valid.merge(df_valid_features, how='left', on='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be71de-f011-43d9-9650-4b374c8b8b7f",
   "metadata": {},
   "source": [
    "### 製作實價登錄不動產租賃之對應特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2461dd9-1cce-4496-a1ca-a2b9db7e51db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:19:30.653364Z",
     "iopub.status.busy": "2023-11-19T19:19:30.653009Z",
     "iopub.status.idle": "2023-11-19T19:19:30.698773Z",
     "shell.execute_reply": "2023-11-19T19:19:30.697826Z"
    }
   },
   "outputs": [],
   "source": [
    "externalkey2subdf = {}\n",
    "key_col = 'key'\n",
    "_new_col_name = ''\n",
    "\n",
    "def get_external_feature_lease(row):\n",
    "    global _new_col_name, _age_in\n",
    "    if row[key_col] not in externalkey2subdf:\n",
    "        return {}\n",
    "    subdf = externalkey2subdf[row[key_col]]\n",
    "    if len(subdf) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        return {\n",
    "            'ID': row['ID'],\n",
    "            f'{_new_col_name}_price_mean': subdf['單價'].mean(),\n",
    "            f'{_new_col_name}_price_std': subdf['單價'].std(),\n",
    "            f'{_new_col_name}_price_max': subdf['單價'].max(),\n",
    "            f'{_new_col_name}_price_min': subdf['單價'].min(),\n",
    "            f'{_new_col_name}_price_max_min_ratio': (subdf['單價'].max()-subdf['單價'].min()) / subdf['單價'].mean(),\n",
    "            f'{_new_col_name}_price_cnt': len(subdf),\n",
    "\n",
    "            f'{_new_col_name}_age_diff_mean': subdf['屋齡'].mean() - row['屋齡'],\n",
    "        }\n",
    "        \n",
    "def mapping_external_gov_data_lease(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by, \n",
    "    new_col_name):\n",
    "    \n",
    "    global _new_col_name\n",
    "    _new_col_name = new_col_name\n",
    "    \n",
    "    df_train[key_col] = df_train[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "    df_valid[key_col] = df_valid[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "    df_external_gov_data[key_col] = df_external_gov_data[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_train[key_col].values.tolist() + df_valid[key_col].values.tolist() + df_external_gov_data[key_col].values.tolist())\n",
    "    df_train[key_col] = le.transform(df_train[key_col].values.tolist())\n",
    "    df_valid[key_col] = le.transform(df_valid[key_col].values.tolist())\n",
    "    df_external_gov_data[key_col] = le.transform(df_external_gov_data[key_col].values.tolist())\n",
    "\n",
    "\n",
    "    \n",
    "    global externalkey2subdf\n",
    "    externalkey2subdf = {}\n",
    "    for key, subdf in df_external_gov_data.groupby(key_col):\n",
    "        externalkey2subdf[key] = subdf\n",
    "    \n",
    "    with Pool(22) as pool:\n",
    "        features = list(tqdm(pool.imap(get_external_feature_lease, df_train.to_dict('records')), total=len(df_train)))\n",
    "    df_train_features = pd.DataFrame(features)\n",
    "    df_train = df_train.merge(df_train_features, how='left', on='ID')\n",
    "    \n",
    "    with Pool(22) as pool:\n",
    "        features = list(tqdm(pool.imap(get_external_feature_lease, df_valid.to_dict('records')), total=len(df_valid)))\n",
    "    df_valid_features = pd.DataFrame(features)\n",
    "    df_valid = df_valid.merge(df_valid_features, how='left', on='ID')\n",
    "    return df_train, df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22637ffb-2b68-4f8b-87c9-abadddc2cb86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:19:30.701142Z",
     "iopub.status.busy": "2023-11-19T19:19:30.700781Z",
     "iopub.status.idle": "2023-11-19T19:19:30.901551Z",
     "shell.execute_reply": "2023-11-19T19:19:30.900419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "int64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "df_external_gov_data = pd.read_csv('../外部資料集/實價登錄/external_gov_data_lease.csv')\n",
    "df_external_gov_data['車位個數'] = df_external_gov_data['車位個數'].astype(int)\n",
    "\n",
    "print(df_train['總樓層數'].dtype)\n",
    "print(df_valid['總樓層數'].dtype)\n",
    "print(df_external_gov_data['總樓層數'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d399b1e-d72d-49c1-a243-7e74bfd61183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:19:30.904355Z",
     "iopub.status.busy": "2023-11-19T19:19:30.904117Z",
     "iopub.status.idle": "2023-11-19T19:19:41.233565Z",
     "shell.execute_reply": "2023-11-19T19:19:41.232905Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 3185.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 3164.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 77.644%, corr = 0.79406\n"
     ]
    }
   ],
   "source": [
    "new_col_name = 'externalkey_lease'\n",
    "df_train, df_valid = mapping_external_gov_data_lease(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by = ['縣市', '鄉鎮市區', '路名', '主要用途', '建物型態'], \n",
    "    new_col_name = new_col_name,\n",
    ")\n",
    "na_cnt = sum(df_train[f'{new_col_name}_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'{new_col_name}_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f84e958a-1d7f-4244-9711-f7ae715f63a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:19:41.236385Z",
     "iopub.status.busy": "2023-11-19T19:19:41.236023Z",
     "iopub.status.idle": "2023-11-19T19:19:51.911871Z",
     "shell.execute_reply": "2023-11-19T19:19:51.911065Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 3266.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 3223.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 63.62%, corr = 0.79442\n"
     ]
    }
   ],
   "source": [
    "new_col_name = 'externalkey_lease_samebuilding'\n",
    "df_train, df_valid = mapping_external_gov_data_lease(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by = ['縣市', '鄉鎮市區', '路名', '主要用途', '建物型態', '總樓層數'], \n",
    "    new_col_name = new_col_name,\n",
    ")\n",
    "na_cnt = sum(df_train[f'{new_col_name}_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'{new_col_name}_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50e8f81b-f048-4c91-ad85-1c929786ef85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:19:51.914346Z",
     "iopub.status.busy": "2023-11-19T19:19:51.914015Z",
     "iopub.status.idle": "2023-11-19T19:20:03.383167Z",
     "shell.execute_reply": "2023-11-19T19:20:03.381959Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 3338.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 3316.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 23.896%, corr = 0.76406\n"
     ]
    }
   ],
   "source": [
    "new_col_name = 'externalkey_lease_samefloor'\n",
    "df_train, df_valid = mapping_external_gov_data_lease(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by = ['縣市', '鄉鎮市區', '路名', '主要用途', '建物型態', '總樓層數', '移轉層次'], \n",
    "    new_col_name = new_col_name,\n",
    ")\n",
    "na_cnt = sum(df_train[f'{new_col_name}_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'{new_col_name}_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1167d38d-8c16-4c3b-9411-b3a5da8ac7d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:20:03.385752Z",
     "iopub.status.busy": "2023-11-19T19:20:03.385467Z",
     "iopub.status.idle": "2023-11-19T19:20:15.014076Z",
     "shell.execute_reply": "2023-11-19T19:20:15.013201Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 3311.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 3304.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 17.607%, corr = 0.75004\n"
     ]
    }
   ],
   "source": [
    "new_col_name = 'externalkey_lease_samefloor_samecar'\n",
    "df_train, df_valid = mapping_external_gov_data_lease(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by = ['縣市', '鄉鎮市區', '路名', '主要用途', '建物型態', '總樓層數', '移轉層次', '車位個數'], \n",
    "    new_col_name = new_col_name,\n",
    ")\n",
    "na_cnt = sum(df_train[f'{new_col_name}_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'{new_col_name}_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c216e7fb-0ef1-4730-82e1-ccd8292bc0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:20:15.016600Z",
     "iopub.status.busy": "2023-11-19T19:20:15.016146Z",
     "iopub.status.idle": "2023-11-19T19:20:26.371040Z",
     "shell.execute_reply": "2023-11-19T19:20:26.370088Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 3373.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 3253.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 46.915%, corr = 0.78198\n"
     ]
    }
   ],
   "source": [
    "df_train['屋齡'] = df_train['屋齡'].astype(int)\n",
    "df_valid['屋齡'] = df_valid['屋齡'].astype(int)\n",
    "df_external_gov_data['屋齡'] = df_external_gov_data['屋齡'].astype(int)\n",
    "\n",
    "new_col_name = 'externalkey_lease_sameage'\n",
    "df_train, df_valid = mapping_external_gov_data_lease(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by = ['縣市', '鄉鎮市區', '路名', '主要用途', '建物型態', '屋齡'], \n",
    "    new_col_name = new_col_name,\n",
    ")\n",
    "na_cnt = sum(df_train[f'{new_col_name}_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'{new_col_name}_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b86872-d482-4def-aa52-901e4cbed0bb",
   "metadata": {},
   "source": [
    "### 製作實價登錄預售屋之對應特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebfefb97-e953-479d-889d-eb5ef690f313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:20:26.375194Z",
     "iopub.status.busy": "2023-11-19T19:20:26.373554Z",
     "iopub.status.idle": "2023-11-19T19:20:26.481344Z",
     "shell.execute_reply": "2023-11-19T19:20:26.480467Z"
    }
   },
   "outputs": [],
   "source": [
    "externalkey2subdf = {}\n",
    "key_col = 'key'\n",
    "_new_col_name = ''\n",
    "\n",
    "def get_external_feature_pre_sale(row):\n",
    "    global _new_col_name, _age_in\n",
    "    if row[key_col] not in externalkey2subdf:\n",
    "        return {}\n",
    "    subdf = externalkey2subdf[row[key_col]]\n",
    "    if len(subdf) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        return {\n",
    "            'ID': row['ID'],\n",
    "            f'{_new_col_name}_price_mean': subdf['單價'].mean(),\n",
    "            f'{_new_col_name}_price_std': subdf['單價'].std(),\n",
    "            f'{_new_col_name}_price_max': subdf['單價'].max(),\n",
    "            f'{_new_col_name}_price_min': subdf['單價'].min(),\n",
    "            f'{_new_col_name}_price_max_min_ratio': (subdf['單價'].max()-subdf['單價'].min()) / subdf['單價'].mean(),\n",
    "            f'{_new_col_name}_price_cnt': len(subdf),\n",
    "        }\n",
    "        \n",
    "def mapping_external_gov_data_pre_sale(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by, \n",
    "    new_col_name):\n",
    "    \n",
    "    global _new_col_name\n",
    "    _new_col_name = new_col_name\n",
    "    \n",
    "    df_train[key_col] = df_train[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "    df_valid[key_col] = df_valid[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "    df_external_gov_data[key_col] = df_external_gov_data[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_train[key_col].values.tolist() + df_valid[key_col].values.tolist() + df_external_gov_data[key_col].values.tolist())\n",
    "    df_train[key_col] = le.transform(df_train[key_col].values.tolist())\n",
    "    df_valid[key_col] = le.transform(df_valid[key_col].values.tolist())\n",
    "    df_external_gov_data[key_col] = le.transform(df_external_gov_data[key_col].values.tolist())\n",
    "\n",
    "\n",
    "    \n",
    "    global externalkey2subdf\n",
    "    externalkey2subdf = {}\n",
    "    for key, subdf in df_external_gov_data.groupby(key_col):\n",
    "        externalkey2subdf[key] = subdf\n",
    "    \n",
    "    with Pool(22) as pool:\n",
    "        features = list(tqdm(pool.imap(get_external_feature_pre_sale, df_train.to_dict('records')), total=len(df_train)))\n",
    "    df_train_features = pd.DataFrame(features)\n",
    "    df_train = df_train.merge(df_train_features, how='left', on='ID')\n",
    "    \n",
    "    with Pool(22) as pool:\n",
    "        features = list(tqdm(pool.imap(get_external_feature_pre_sale, df_valid.to_dict('records')), total=len(df_valid)))\n",
    "    df_valid_features = pd.DataFrame(features)\n",
    "    df_valid = df_valid.merge(df_valid_features, how='left', on='ID')\n",
    "    return df_train, df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1ca80b0-d4c6-4ef3-9262-9deb1fce51e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:20:26.483767Z",
     "iopub.status.busy": "2023-11-19T19:20:26.483530Z",
     "iopub.status.idle": "2023-11-19T19:20:26.842894Z",
     "shell.execute_reply": "2023-11-19T19:20:26.841924Z"
    }
   },
   "outputs": [],
   "source": [
    "df_external_gov_data = pd.read_csv('../外部資料集/實價登錄/external_gov_data_pre_sale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55a0cba5-9a0d-4c02-8707-c0ec75e59f5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:20:26.845727Z",
     "iopub.status.busy": "2023-11-19T19:20:26.845535Z",
     "iopub.status.idle": "2023-11-19T19:20:36.943341Z",
     "shell.execute_reply": "2023-11-19T19:20:36.942173Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 3245.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 3246.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 31.453%, corr = 0.81748\n"
     ]
    }
   ],
   "source": [
    "new_col_name = 'externalkey_pre_sale'\n",
    "df_train, df_valid = mapping_external_gov_data_pre_sale(\n",
    "    df_train, \n",
    "    df_valid, \n",
    "    df_external_gov_data, \n",
    "    by = ['縣市', '鄉鎮市區', '路名'], \n",
    "    new_col_name = new_col_name,\n",
    ")\n",
    "na_cnt = sum(df_train[f'{new_col_name}_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'{new_col_name}_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5dfe8d-b520-405c-b72e-bbf24490f915",
   "metadata": {},
   "source": [
    "### 基於實際距離(以訓練資料來獲得每個路名的中心點位置)製作實價登錄不動產交易之相關特徵\n",
    "### 每段路如果中心點距離不超過500公尺，則會視做同一群體，詳見road_near_road_infos這個變數的生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84ee1e43-fab4-4ff1-9237-eac321fe72fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:20:36.946670Z",
     "iopub.status.busy": "2023-11-19T19:20:36.946424Z",
     "iopub.status.idle": "2023-11-19T19:20:39.075783Z",
     "shell.execute_reply": "2023-11-19T19:20:39.074919Z"
    }
   },
   "outputs": [],
   "source": [
    "df_external_gov_data = pd.read_csv('../外部資料集/實價登錄/external_gov_data.csv')\n",
    "\n",
    "key_col = 'key'\n",
    "by = ['縣市', '鄉鎮市區', '路名']\n",
    "\n",
    "df_train[key_col] = df_train[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "df_valid[key_col] = df_valid[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "df_external_gov_data[key_col] = df_external_gov_data[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train[key_col].values.tolist() + df_valid[key_col].values.tolist() + df_external_gov_data[key_col].values.tolist())\n",
    "df_train[key_col] = le.transform(df_train[key_col].values.tolist())\n",
    "df_valid[key_col] = le.transform(df_valid[key_col].values.tolist())\n",
    "df_external_gov_data[key_col] = le.transform(df_external_gov_data[key_col].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "616dfe2c-ec4f-4ac6-b502-adc2ab5712a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:20:39.078241Z",
     "iopub.status.busy": "2023-11-19T19:20:39.078022Z",
     "iopub.status.idle": "2023-11-19T19:21:11.350564Z",
     "shell.execute_reply": "2023-11-19T19:21:11.349989Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4829/4829 [00:31<00:00, 153.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4829/4829 [00:00<00:00, 1750435.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4829.000000</td>\n",
       "      <td>4829.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5425.932905</td>\n",
       "      <td>5.179954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3163.523331</td>\n",
       "      <td>3.508146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2392.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5520.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7810.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11198.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                key          len\n",
       "count   4829.000000  4829.000000\n",
       "mean    5425.932905     5.179954\n",
       "std     3163.523331     3.508146\n",
       "min        0.000000     0.000000\n",
       "25%     2392.000000     2.000000\n",
       "50%     5520.000000     5.000000\n",
       "75%     7810.000000     7.000000\n",
       "max    11198.000000    23.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 500\n",
    "\n",
    "tmp_use_cols = [key_col, 'twd97_lon', 'twd97_lat']\n",
    "df_all = pd.concat([df_train[tmp_use_cols], df_valid[tmp_use_cols]]).reset_index(drop=True)\n",
    "\n",
    "road_coordinates = {}\n",
    "\n",
    "for key, subdf in df_all.groupby(key_col):\n",
    "    road_coordinates[key] = (subdf['twd97_lon'].median(), subdf['twd97_lat'].median())\n",
    "\n",
    "road_near_road_infos = {}\n",
    "for key1 in tqdm(road_coordinates.keys()):\n",
    "    road_near_road_infos[key1] = []\n",
    "    for key2 in road_coordinates.keys():\n",
    "        if key1 == key2:\n",
    "            continue\n",
    "        distance = get_distance_without_cache(road_coordinates[key1][1], road_coordinates[key1][0], road_coordinates[key2][1], road_coordinates[key2][0])\n",
    "        if distance <= threshold:\n",
    "            road_near_road_infos[key1].append(key2)\n",
    "\n",
    "tmp_datas = []\n",
    "for key1 in tqdm(road_near_road_infos.keys()):\n",
    "    tmp_datas.append({\n",
    "        'key': key1,\n",
    "        'len': len(road_near_road_infos[key1])\n",
    "    })\n",
    "tmp_df = pd.DataFrame(tmp_datas)\n",
    "tmp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81cd0b90-57d7-4fe2-8445-e16ada19a85d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:21:11.352538Z",
     "iopub.status.busy": "2023-11-19T19:21:11.352277Z",
     "iopub.status.idle": "2023-11-19T19:21:22.120663Z",
     "shell.execute_reply": "2023-11-19T19:21:22.119985Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:03<00:00, 2997.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:04<00:00, 2929.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 84.52%, corr = 0.89327\n"
     ]
    }
   ],
   "source": [
    "externalkey2subdf = {}\n",
    "for key, subdf in df_external_gov_data.groupby(key_col):\n",
    "    externalkey2subdf[key] = subdf\n",
    "\n",
    "def get_external_same_building_feature(row):\n",
    "    nearby_roads = road_near_road_infos[row[key_col]]\n",
    "    if len(nearby_roads) == 0:\n",
    "        return {}\n",
    "    subdfs = []\n",
    "    for nearby_road in nearby_roads:\n",
    "        if nearby_road in externalkey2subdf:\n",
    "            subdfs.append(externalkey2subdf[nearby_road])\n",
    "    if len(subdfs) == 0:\n",
    "        return {}\n",
    "    subdf = pd.concat(subdfs).reset_index(drop=True)\n",
    "    subdf = subdf.query(f'建物型態 == \"{row[\"建物型態\"]}\" and 主要用途 == \"{row[\"主要用途\"]}\"')\n",
    "    if len(subdf) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        return {\n",
    "            'ID': row['ID'],\n",
    "            'externalkey_nearby_roads_price_mean': subdf['單價'].mean(),\n",
    "            'externalkey_nearby_roads_price_std': subdf['單價'].std(),\n",
    "        }\n",
    "\n",
    "with Pool(22) as pool:\n",
    "    features = list(tqdm(pool.imap(get_external_same_building_feature, df_train.to_dict('records')), total=len(df_train)))\n",
    "df_train_features = pd.DataFrame(features)\n",
    "df_train = df_train.merge(df_train_features, how='left', on='ID')\n",
    "\n",
    "with Pool(22) as pool:\n",
    "    features = list(tqdm(pool.imap(get_external_same_building_feature, df_valid.to_dict('records')), total=len(df_valid)))\n",
    "df_valid_features = pd.DataFrame(features)\n",
    "df_valid = df_valid.merge(df_valid_features, how='left', on='ID')\n",
    "\n",
    "\n",
    "na_cnt = sum(df_train[f'externalkey_nearby_roads_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'externalkey_nearby_roads_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25ff2a-686e-41ab-83fc-5af2b3322194",
   "metadata": {},
   "source": [
    "### 原始資料集基於 縣市+鄉鎮市區+路名+總樓層數+主要用途+建物型態 所建之相關單價、屋齡、面積之統計特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2dbb34af-a045-474f-aeb1-66556943769e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:21:22.122800Z",
     "iopub.status.busy": "2023-11-19T19:21:22.122474Z",
     "iopub.status.idle": "2023-11-19T19:22:01.314114Z",
     "shell.execute_reply": "2023-11-19T19:22:01.313257Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████████████████████████                                                             | 5785/11751 [00:11<00:07, 786.45it/s]/tmp/ipykernel_21508/4291528695.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  'key_age_max_min_ratio': (subdf['age'].max()-subdf['age'].min()) / subdf['age'].mean(),\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:21<00:00, 549.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:13<00:00, 842.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping_rate = 55.57%, corr = 0.93881\n"
     ]
    }
   ],
   "source": [
    "key_col = 'key'\n",
    "by = ['縣市', '鄉鎮市區', '路名', '主要用途', '建物型態', '總樓層數']\n",
    "\n",
    "df_train[key_col] = df_train[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "df_valid[key_col] = df_valid[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "df_external_gov_data[key_col] = df_external_gov_data[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train[key_col].values.tolist() + df_valid[key_col].values.tolist() + df_external_gov_data[key_col].values.tolist())\n",
    "df_train[key_col] = le.transform(df_train[key_col].values.tolist())\n",
    "df_valid[key_col] = le.transform(df_valid[key_col].values.tolist())\n",
    "df_external_gov_data[key_col] = le.transform(df_external_gov_data[key_col].values.tolist())\n",
    "\n",
    "key2subdf = {}\n",
    "for key, subdf in df_train.groupby(key_col):\n",
    "    key2subdf[key] = subdf\n",
    "\n",
    "def get_same_building_feature(row):\n",
    "    if row[key_col] not in key2subdf:\n",
    "        return {}\n",
    "    subdf = key2subdf[row[key_col]].query(f'ID != \"{row[\"ID\"]}\"')\n",
    "    if len(subdf) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        return {\n",
    "            'ID': row['ID'],\n",
    "            'key_price_mean': subdf['price'].mean(),\n",
    "            'key_price_std': subdf['price'].std(),\n",
    "            'key_price_max': subdf['price'].max(),\n",
    "            'key_price_min': subdf['price'].min(),\n",
    "            'key_price_max_min_ratio': (subdf['price'].max()-subdf['price'].min()) / subdf['price'].mean(),\n",
    "            'key_price_cnt': len(subdf),\n",
    "            \n",
    "            'key_age_mean': subdf['age'].mean(),\n",
    "            'key_age_std': subdf['age'].std(),\n",
    "            'key_age_max': subdf['age'].max(),\n",
    "            'key_age_min': subdf['age'].min(),\n",
    "            'key_age_max_min_ratio': (subdf['age'].max()-subdf['age'].min()) / subdf['age'].mean(),\n",
    "            #'key_age_divided_diff': subdf['age'].mean() / row['age'],\n",
    "            'key_age_minus_diff':  row['age'] - subdf['age'].mean(),\n",
    "            \n",
    "            'key_building_area_minus_room_area_mean': subdf['building_area_minus_room_area'].mean(),\n",
    "            'key_building_area_minus_room_area_std': subdf['building_area_minus_room_area'].std(),\n",
    "            'key_building_area_minus_room_area_min': subdf['building_area_minus_room_area'].min(),\n",
    "            'key_building_area_minus_room_area_max': subdf['building_area_minus_room_area'].max(),\n",
    "            \n",
    "            'key_room_area_minus_building_area_mean': subdf['room_area_minus_building_area'].mean(),\n",
    "            'key_room_area_minus_building_area_std': subdf['room_area_minus_building_area'].std(),\n",
    "            'key_room_area_minus_building_area_min': subdf['room_area_minus_building_area'].min(),\n",
    "            'key_room_area_minus_building_area_max': subdf['room_area_minus_building_area'].max(),\n",
    "        }\n",
    "with Pool(22) as pool:\n",
    "    features = list(tqdm(pool.imap(get_same_building_feature, df_train.to_dict('records')), total=len(df_train)))\n",
    "df_train_features = pd.DataFrame(features)\n",
    "df_train = df_train.merge(df_train_features, how='left', on='ID')\n",
    "\n",
    "with Pool(22) as pool:\n",
    "    features = list(tqdm(pool.imap(get_same_building_feature, df_valid.to_dict('records')), total=len(df_valid)))\n",
    "df_valid_features = pd.DataFrame(features)\n",
    "df_valid = df_valid.merge(df_valid_features, how='left', on='ID')\n",
    "\n",
    "na_cnt = sum(df_train[f'key_price_mean'].isna())\n",
    "mapping_rate = 1 - na_cnt / len(df_train)\n",
    "corr = df_train[['單價', f'key_price_mean']].corr().iloc[0].values[1]\n",
    "print(f'mapping_rate = {round(mapping_rate*100, 3)}%, corr = {round(corr, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdc55f8-cc9c-4fae-a99c-665f554fb8f0",
   "metadata": {},
   "source": [
    "### 原始資料集基於 縣市+鄉鎮市區+主要用途+建物型態 所建之相關 屋齡 之統計特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af604dc6-dec9-4487-b74f-7e196d5f2422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:22:01.316593Z",
     "iopub.status.busy": "2023-11-19T19:22:01.316255Z",
     "iopub.status.idle": "2023-11-19T19:22:31.618821Z",
     "shell.execute_reply": "2023-11-19T19:22:31.617806Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:13<00:00, 839.54it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11751/11751 [00:12<00:00, 916.93it/s]\n"
     ]
    }
   ],
   "source": [
    "key_col = 'key'\n",
    "by = ['縣市', '鄉鎮市區', '主要用途', '建物型態']\n",
    "\n",
    "df_train[key_col] = df_train[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "df_valid[key_col] = df_valid[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "df_external_gov_data[key_col] = df_external_gov_data[by].apply(lambda x: '_'.join([str(v) for v in x]), axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train[key_col].values.tolist() + df_valid[key_col].values.tolist() + df_external_gov_data[key_col].values.tolist())\n",
    "df_train[key_col] = le.transform(df_train[key_col].values.tolist())\n",
    "df_valid[key_col] = le.transform(df_valid[key_col].values.tolist())\n",
    "df_external_gov_data[key_col] = le.transform(df_external_gov_data[key_col].values.tolist())\n",
    "\n",
    "key2subdf = {}\n",
    "for key, subdf in df_train.groupby(key_col):\n",
    "    key2subdf[key] = subdf\n",
    "\n",
    "def get_same_building_feature(row):\n",
    "    if row[key_col] not in key2subdf:\n",
    "        return {}\n",
    "    subdf = key2subdf[row[key_col]].query(f'ID != \"{row[\"ID\"]}\"')\n",
    "    if len(subdf) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        return {\n",
    "            'ID': row['ID'],\n",
    "            'key_city12_age_mean': subdf['age'].mean(),\n",
    "            'key_city12_age_std': subdf['age'].std(),\n",
    "            'key_city12_age_max': subdf['age'].max(),\n",
    "            'key_city12_age_min': subdf['age'].min(),\n",
    "            'key_city12_age_max_min_ratio': (subdf['age'].max()-subdf['age'].min()) / subdf['age'].mean(),\n",
    "            #'key_city12_age_divided_diff': subdf['age'].mean() / row['age'],\n",
    "            'key_city12_age_minus_diff':  row['age'] - subdf['age'].mean(),\n",
    "        }\n",
    "with Pool(22) as pool:\n",
    "    features = list(tqdm(pool.imap(get_same_building_feature, df_train.to_dict('records')), total=len(df_train)))\n",
    "df_train_features = pd.DataFrame(features)\n",
    "df_train = df_train.merge(df_train_features, how='left', on='ID')\n",
    "\n",
    "with Pool(22) as pool:\n",
    "    features = list(tqdm(pool.imap(get_same_building_feature, df_valid.to_dict('records')), total=len(df_valid)))\n",
    "df_valid_features = pd.DataFrame(features)\n",
    "df_valid = df_valid.merge(df_valid_features, how='left', on='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89886291-7dbe-4ae5-9b56-a58257ed5a80",
   "metadata": {},
   "source": [
    "### 各種方式獲得的均價特徵的再製造(彼此相減)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a611c4f-5d38-4c37-a31d-341f8c293938",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:22:31.622430Z",
     "iopub.status.busy": "2023-11-19T19:22:31.621944Z",
     "iopub.status.idle": "2023-11-19T19:22:31.629335Z",
     "shell.execute_reply": "2023-11-19T19:22:31.628346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_mean_cols = [c for c in df_train.columns if c.endswith('_price_mean')]\n",
    "price_mean_cols = [\n",
    "    'ref_500_price_mean',\n",
    "    'ref_1200_price_mean',\n",
    "    'ref_3600_price_mean',\n",
    "    'nearest_100_price_mean',\n",
    "    'nearest_30_price_mean',\n",
    "    'nearest_4_price_mean',\n",
    "    'city12_price_mean',\n",
    "    'key_price_mean',\n",
    "    'externalkey_price_mean',\n",
    "    'externalkey_samebuilding_price_mean',\n",
    "    'externalkey_sameage_price_mean',\n",
    "    'externalkey_sameage_0.25_price_mean',\n",
    "    #'externalkey_nearby_roads_price_mean',\n",
    "    #'key_nearyby_roads_price_mean'\n",
    "]\n",
    "len(price_mean_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ab00fdb-529a-4783-a56c-e5e12db6a062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:22:31.631503Z",
     "iopub.status.busy": "2023-11-19T19:22:31.631281Z",
     "iopub.status.idle": "2023-11-19T19:22:31.693801Z",
     "shell.execute_reply": "2023-11-19T19:22:31.693219Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2093291354.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n"
     ]
    }
   ],
   "source": [
    "for price_mean_col1 in price_mean_cols:\n",
    "    for price_mean_col2 in price_mean_cols:\n",
    "        if price_mean_col1 == price_mean_col2:\n",
    "            continue\n",
    "        new_col = f'price_minus_feature_{price_mean_col1}_minus_{price_mean_col2}'\n",
    "        df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
    "        df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bce6a7a2-a1e5-41df-a31b-819fc7e229df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:22:31.695790Z",
     "iopub.status.busy": "2023-11-19T19:22:31.695588Z",
     "iopub.status.idle": "2023-11-19T19:22:31.710137Z",
     "shell.execute_reply": "2023-11-19T19:22:31.709540Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21508/2168345414.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
      "/tmp/ipykernel_21508/2168345414.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]\n"
     ]
    }
   ],
   "source": [
    "price_mean_cols = [\n",
    "    'ref_500_price_mean',\n",
    "    'ref_1200_price_mean',\n",
    "    'ref_3600_price_mean',\n",
    "    'nearest_100_price_mean',\n",
    "    'nearest_30_price_mean',\n",
    "    'nearest_4_price_mean',\n",
    "    'city12_price_mean',\n",
    "    'key_price_mean',\n",
    "    'externalkey_price_mean',\n",
    "    'externalkey_samebuilding_price_mean',\n",
    "    'externalkey_sameage_price_mean',\n",
    "    'externalkey_sameage_0.25_price_mean',\n",
    "]\n",
    "\n",
    "for price_mean_col1 in ['externalkey_exactly_same_price_mean']:\n",
    "    for price_mean_col2 in price_mean_cols:\n",
    "        if price_mean_col1 == price_mean_col2:\n",
    "            continue\n",
    "        new_col = f'price_minus_feature_{price_mean_col1}_minus_{price_mean_col2}'\n",
    "        df_train[new_col] = df_train[price_mean_col1] - df_train[price_mean_col2]\n",
    "        df_valid[new_col] = df_valid[price_mean_col1] - df_valid[price_mean_col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8159b2-2cff-4122-bf57-9ed65e3b1720",
   "metadata": {},
   "source": [
    "### 額外資料特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23500ffa-2ff8-4960-add7-96b432e81cdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:22:31.712460Z",
     "iopub.status.busy": "2023-11-19T19:22:31.712257Z",
     "iopub.status.idle": "2023-11-19T19:22:31.845698Z",
     "shell.execute_reply": "2023-11-19T19:22:31.844930Z"
    }
   },
   "outputs": [],
   "source": [
    "df_low_income = pd.read_csv('../外部資料集/low_income_info.csv')\n",
    "df_train = df_train.merge(df_low_income, how='left', on=['縣市', '鄉鎮市區'])\n",
    "df_valid = df_valid.merge(df_low_income, how='left', on=['縣市', '鄉鎮市區'])\n",
    "\n",
    "df_population = pd.read_csv('../外部資料集/population_info.csv')\n",
    "df_train = df_train.merge(df_population, how='left', on=['縣市', '鄉鎮市區'])\n",
    "df_valid = df_valid.merge(df_population, how='left', on=['縣市', '鄉鎮市區'])\n",
    "\n",
    "column_transforms = {\n",
    "    '低收入戶戶數': 'low_income_group_cnt',\n",
    "    '低收入戶人口數': 'low_income_people_cnt',\n",
    "    '行政區人口數': 'population_cnt',\n",
    "    '行政區土地面積': 'population_area',\n",
    "    '行政區人口密度': 'population_density'\n",
    "}\n",
    "for col, new_col in column_transforms.items():\n",
    "    df_train[new_col] = df_train[col].values\n",
    "    df_valid[new_col] = df_valid[col].values\n",
    "\n",
    "df_train['low_income_rate'] = df_train['低收入戶人口數'] / df_train['行政區人口數']\n",
    "df_valid['low_income_rate'] = df_valid['低收入戶人口數'] / df_valid['行政區人口數']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c400cb13-913b-475a-90f2-1dfb90f8d25a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:22:31.848706Z",
     "iopub.status.busy": "2023-11-19T19:22:31.848503Z",
     "iopub.status.idle": "2023-11-19T19:22:31.863889Z",
     "shell.execute_reply": "2023-11-19T19:22:31.863233Z"
    }
   },
   "outputs": [],
   "source": [
    "area_cols1 = [\n",
    "    'room_area', \n",
    "    'car_area',\n",
    "    'building_area',\n",
    "]\n",
    "area_cols2 = [\n",
    "    'externalkey_land2_mean',\n",
    "    'externalkey_land3_mean',\n",
    "    'externalkey_land4_mean',\n",
    "    'externalkey_samebuilding_land2_mean',\n",
    "    'externalkey_samebuilding_land3_mean',\n",
    "    'externalkey_samebuilding_land4_mean',\n",
    "]\n",
    "new_area_cols = []\n",
    "for area_col1 in area_cols1:\n",
    "    for area_col2 in area_cols2:\n",
    "        if area_col1 == area_col2:\n",
    "            continue\n",
    "        df_train[f'{area_col1}_minus_{area_col2}'] = df_train[area_col1] - df_train[area_col2]\n",
    "        df_valid[f'{area_col1}_minus_{area_col2}'] = df_valid[area_col1] - df_valid[area_col2]\n",
    "        new_area_cols.append(f'{area_col1}_minus_{area_col2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4dbb4336-fc7e-4254-b172-e2d786bdcb4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:22:31.866238Z",
     "iopub.status.busy": "2023-11-19T19:22:31.866070Z",
     "iopub.status.idle": "2023-11-19T19:22:31.888624Z",
     "shell.execute_reply": "2023-11-19T19:22:31.887727Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_floor_cat(floor):\n",
    "    if floor <= 3:\n",
    "        return 1\n",
    "    elif floor <= 6:\n",
    "        return 2\n",
    "    elif floor <= 12:\n",
    "        return 3\n",
    "    elif floor < 20:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "def get_age_cat(age):\n",
    "    if age <= 2:\n",
    "        return 1\n",
    "    elif age <= 5:\n",
    "        return 2\n",
    "    elif age <= 10:\n",
    "        return 3\n",
    "    elif age <= 20:\n",
    "        return 4\n",
    "    elif age <= 30:\n",
    "        return 5\n",
    "    elif age <= 40:\n",
    "        return 6\n",
    "    return 7\n",
    "    \n",
    "df_train['floor_cat'] = df_train['floor'].apply(get_floor_cat)\n",
    "df_valid['floor_cat'] = df_valid['floor'].apply(get_floor_cat)\n",
    "df_train['total_floor_cat'] = df_train['total_floor'].apply(get_floor_cat)\n",
    "df_valid['total_floor_cat'] = df_valid['total_floor'].apply(get_floor_cat)\n",
    "df_train['age_cat'] = df_train['age'].apply(get_age_cat)\n",
    "df_valid['age_cat'] = df_valid['age'].apply(get_age_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df49c857-156b-42d8-ac0c-3088d5b6eed1",
   "metadata": {},
   "source": [
    "### 移除不必要的欄位，這邊用.isascii()來刪除原始的欄位，僅保留alphabet的欄位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fed98f0d-c24f-44c6-8c5b-1d07a370062c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:22:31.890327Z",
     "iopub.status.busy": "2023-11-19T19:22:31.890144Z",
     "iopub.status.idle": "2023-11-19T19:22:31.893087Z",
     "shell.execute_reply": "2023-11-19T19:22:31.892424Z"
    }
   },
   "outputs": [],
   "source": [
    "use_cols = [c for c in df_train.columns if c.isascii()]\n",
    "use_cols = [c for c in use_cols if c != 'key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d9188ab-deef-4695-a04b-413a491eaf69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:22:31.894887Z",
     "iopub.status.busy": "2023-11-19T19:22:31.894464Z",
     "iopub.status.idle": "2023-11-19T19:22:45.231960Z",
     "shell.execute_reply": "2023-11-19T19:22:45.231306Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train[use_cols].to_csv('../官方資料集/final_feature_engineering_train.csv', index=False)\n",
    "df_valid[use_cols].to_csv('../官方資料集/final_feature_engineering_valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "074df1c0-9b50-4ee3-842e-a13c74d41bea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T19:22:45.234394Z",
     "iopub.status.busy": "2023-11-19T19:22:45.234037Z",
     "iopub.status.idle": "2023-11-19T19:22:45.237900Z",
     "shell.execute_reply": "2023-11-19T19:22:45.237354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30776ebf-6c59-4e58-90eb-ebb9f21d828a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc1c848-b815-42aa-ae4e-9135f68baf07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2041d948-9485-4d6c-95b2-6264db28ba66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
