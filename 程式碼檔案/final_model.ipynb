{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1e478e-a385-42d4-8a46-c254d09b8586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "from tqdm import tqdm\n",
    "import folium\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import random\n",
    "import haversine as hs\n",
    "from multiprocessing import Pool\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import neighbors\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "N_FOLD = 20\n",
    "sub_prefix = 'submission'\n",
    "\n",
    "random.seed(1994)\n",
    "np.random.seed(1994)\n",
    "tqdm.pandas()\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['font.sans-serif'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False # 顯示負號\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "\n",
    "start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e4fae-f54b-4c41-9e50-fc58b35332a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_model(x, y, oof_x, oof_y, test_x, categorical_feature, feature_name):\n",
    "    catboost_params = {\n",
    "        'learning_rate': 0.03,\n",
    "        'depth': 8,\n",
    "        'iterations': 5000,\n",
    "        'loss_function': 'RMSE',\n",
    "        'eval_metric': 'MAPE',\n",
    "        'thread_count': 22,\n",
    "        'cat_features': categorical_feature,\n",
    "        'bagging_temperature': 0.95\n",
    "    }\n",
    "\n",
    "    y = np.log(y)\n",
    "    oof_y = np.log(oof_y)\n",
    "    \n",
    "    model = CatBoostRegressor(**catboost_params)\n",
    "    model.fit(x, y, eval_set=(oof_x, oof_y), use_best_model=True, early_stopping_rounds=200, verbose=1000)\n",
    "    \n",
    "    oof = model.predict(oof_x)\n",
    "    preds = model.predict(test_x)\n",
    "    \n",
    "    return np.exp(oof), np.exp(preds), model\n",
    "\n",
    "def xgboost_model(x, y, oof_x, oof_y, test_x, categorical_feature, feature_name):\n",
    "    xgb_params = {\n",
    "        'objective': 'reg:squaredlogerror',\n",
    "        'learning_rate': 0.02,\n",
    "        'max_depth': 7,\n",
    "        'n_estimators': 4000,\n",
    "        'subsample': 0.88,\n",
    "        'colsample_bytree': 0.55,\n",
    "        'verbosity': 1,\n",
    "        'n_jobs': 22,\n",
    "        'eval_metric': 'mape'\n",
    "    }\n",
    "    \n",
    "    d_train = xgb.DMatrix(x, label=y)\n",
    "    d_valid = xgb.DMatrix(oof_x, label=oof_y)\n",
    "    \n",
    "    model = xgb.train(xgb_params, d_train, num_boost_round=xgb_params['n_estimators'], evals=[(d_valid, 'valid')], early_stopping_rounds=200, feval=None, maximize=False, verbose_eval=1000)\n",
    "    \n",
    "    oof = model.predict(d_valid)\n",
    "    preds = model.predict(xgb.DMatrix(test_x))\n",
    "    \n",
    "    return oof, preds, model\n",
    "\n",
    "def lgb_model(x, y, oof_x, oof_y, test_x, categorical_feature, feature_name):\n",
    "    lgb_params = {\n",
    "        'learning_rate': 0.01,\n",
    "        'application': 'regression',\n",
    "        'max_depth': 8,\n",
    "        'num_leaves': 256,\n",
    "        'feature_fraction': 0.44,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 8,\n",
    "        'verbosity': -1,\n",
    "        'metric': 'mape',\n",
    "        'num_threads': 22,\n",
    "        'num_iterations': 7000\n",
    "    }\n",
    "    \n",
    "    y = np.log(y)\n",
    "    oof_y = np.log(oof_y)\n",
    "    \n",
    "    callbacks = [lgb.log_evaluation(period=1000), lgb.early_stopping(stopping_rounds=200)]\n",
    "    \n",
    "    d_train = lgb.Dataset(x, label=y)\n",
    "    d_valid = lgb.Dataset(oof_x, label=oof_y)\n",
    "    \n",
    "    model = lgb.train(lgb_params, train_set=d_train, valid_sets=d_valid, callbacks=callbacks, feature_name=feature_name, categorical_feature=categorical_feature)\n",
    "\n",
    "    oof = model.predict(oof_x)\n",
    "    preds = model.predict(test_x)\n",
    "    return np.exp(oof), np.exp(preds), model\n",
    "\n",
    "def knn_model(x, y, oof_x, oof_y, test_x):\n",
    "    scaler = StandardScaler()\n",
    "    x = scaler.fit_transform(x)\n",
    "    oof_x = scaler.transform(oof_x)\n",
    "    test_x = scaler.transform(test_x)\n",
    "    model = neighbors.KNeighborsRegressor(min(7, len(x), len(oof_x)), n_jobs=22)\n",
    "    model.fit(x, y)\n",
    "    oof = model.predict(oof_x)\n",
    "    preds = model.predict(test_x)\n",
    "    return oof, preds\n",
    "\n",
    "\n",
    "class mape_tabnet(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"MAPE\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "        return mape\n",
    "\n",
    "def tabnet_model(x, y, oof_x, oof_y, test_x):\n",
    "    scaler = StandardScaler()\n",
    "    x = scaler.fit_transform(x)\n",
    "    oof_x = scaler.transform(oof_x)\n",
    "    test_x = scaler.transform(test_x)\n",
    "\n",
    "    # 定義 TabNet 模型\n",
    "    model = TabNetRegressor(\n",
    "        #scheduler_params={\"step_size\":10, \"gamma\":0.95}\n",
    "    )\n",
    "    \n",
    "    # 訓練模型，提供 early stopping\n",
    "    model.fit(\n",
    "        X_train=x, y_train=y.reshape(-1, 1),\n",
    "        eval_set=[(oof_x, oof_y.reshape(-1, 1))],\n",
    "        eval_name=[\"valid\"],\n",
    "        eval_metric=[mape_tabnet],\n",
    "        max_epochs=200,  # 設定最大迭代次數\n",
    "        patience=20,  # 設定 early stopping 的耐心度\n",
    "        batch_size=1024,  # 設定批量大小\n",
    "        num_workers=22,\n",
    "        virtual_batch_size=1024,  # 設定虛擬批量大小\n",
    "    )\n",
    "\n",
    "    # 預測測試集\n",
    "    preds = model.predict(test_x).flatten()\n",
    "    oof = model.predict(oof_x).flatten()\n",
    "    return oof, preds, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e3297e-b5c6-4770-a680-a5616b9ed3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_test, pred):\n",
    "    y_test, pred = np.array(y_test), np.array(pred)\n",
    "    mape = np.mean(np.abs((y_test - pred) / y_test))\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7382c9-186e-41e9-9a95-1f584a0a90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../官方資料集/final_feature_engineering_train.csv')\n",
    "df_valid = pd.read_csv('../官方資料集/final_feature_engineering_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f53de0d-e658-4abe-849a-ffb0ab011714",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = [c for c in df_train.columns if c.isascii()]\n",
    "use_cols.remove('ID')\n",
    "use_cols.remove('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b88307a-c39b-4b47-b25e-30e627f4642f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_corr(a, b):\n",
    "    _a = []\n",
    "    _b = []\n",
    "    for v1, v2 in zip(a, b):\n",
    "        if v1 > -9999 and v2 > -9999:\n",
    "            _a.append(v1)\n",
    "            _b.append(v2)\n",
    "    return np.corrcoef(_a, _b)[0][1]\n",
    "\n",
    "def corr_job(cols):\n",
    "    c1, c2 = cols[0], cols[1]\n",
    "    corr = get_corr(df_train[c1].values, df_train[c2].values)\n",
    "    return {\n",
    "        'key': f'{c1}_{c2}',\n",
    "        'corr': corr\n",
    "    }\n",
    "\n",
    "job_cols = []\n",
    "for c1 in tqdm(use_cols):\n",
    "    for c2 in use_cols:\n",
    "        if c1 == c2:\n",
    "            continue\n",
    "        job_cols.append([c1, c2])\n",
    "\n",
    "with Pool(22) as pool:\n",
    "    column_corrs = list(tqdm(pool.imap(corr_job, job_cols), total=len(job_cols)))\n",
    "\n",
    "corr_dict = {}\n",
    "for d in column_corrs:\n",
    "    corr_dict.update({\n",
    "        d['key']: d['corr']\n",
    "    })\n",
    "corr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a819599e-608a-4f52-a8d3-1871ed7def85",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = []\n",
    "\n",
    "for c1 in tqdm(use_cols):\n",
    "    for c2 in use_cols:\n",
    "        if c1 == c2:\n",
    "            continue\n",
    "        if c1 in remove_cols:\n",
    "            continue\n",
    "        if c2 in remove_cols:\n",
    "            continue\n",
    "        key = f'{c1}_{c2}'\n",
    "        corr = corr_dict[key]\n",
    "        if corr > 0.999:\n",
    "            if 'mean' not in c2:\n",
    "                print(c1, c2, corr)\n",
    "                remove_cols.append(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e5a158-a1ab-419b-88a5-c6d211f83e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_cols = []\n",
    "for c in df_train.columns:\n",
    "    na_cnt1 = sum(df_train[c].isna())\n",
    "    na_cnt2 = sum(df_valid[c].isna())\n",
    "    if na_cnt1 >= len(df_train)*0.8 or na_cnt2 >= len(df_valid)*0.8:\n",
    "        na_cols.append(c)\n",
    "        print(c, na_cnt1, na_cnt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c8a12-2ea7-475e-bbcc-f062de09be80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(use_cols))\n",
    "use_cols = [c for c in use_cols if c not in remove_cols]\n",
    "print(len(use_cols))\n",
    "use_cols = [c for c in use_cols if c not in na_cols]\n",
    "print(len(use_cols))\n",
    "print(use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa7601-1d33-4029-9cd9-53ee848e63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature = [\n",
    "    use_cols.index('city_1'),\n",
    "    use_cols.index('city_2'),\n",
    "    use_cols.index('city_3'),\n",
    "    use_cols.index('city12'),\n",
    "    use_cols.index('building_type'),\n",
    "    use_cols.index('main_material'),\n",
    "    use_cols.index('main_usage'),\n",
    "    use_cols.index('use_type'),\n",
    "    use_cols.index('floor_cat'),\n",
    "    use_cols.index('total_floor_cat'),\n",
    "    use_cols.index('age_cat'),\n",
    "]\n",
    "for i in categorical_feature:\n",
    "    col = use_cols[i]\n",
    "    df_train[col] = df_train[col].astype(int)\n",
    "    df_valid[col] = df_valid[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3383ff-1421-4e2a-8dfa-2bc257b81c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d2f53-1230-48a1-a9f2-044425bdd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_hour = (datetime.datetime.now()-start).total_seconds() / 60 / 60\n",
    "print(f'準備完成即將開始訓練，目前花費 {use_hour} 小時')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625aa78f-5bba-49ab-bcbc-1bfa10beb7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dict = {\n",
    "    'knn': {\n",
    "        'oof': np.zeros(len(df_train)),\n",
    "        'test': np.zeros(len(df_valid))\n",
    "    },\n",
    "    'tabnet': {\n",
    "        'oof': np.zeros(len(df_train)),\n",
    "        'test': np.zeros(len(df_valid))\n",
    "    },\n",
    "    'xgb': {\n",
    "        'oof': np.zeros(len(df_train)),\n",
    "        'test': np.zeros(len(df_valid)),\n",
    "        'stage1_models': [None for _ in range(N_FOLD)],\n",
    "        'stage2_models': [None for _ in range(N_FOLD)]\n",
    "    },\n",
    "    'lgb': {\n",
    "        'oof': np.zeros(len(df_train)),\n",
    "        'test': np.zeros(len(df_valid)),\n",
    "        'stage1_models': [None for _ in range(N_FOLD)],\n",
    "        'stage2_models': [None for _ in range(N_FOLD)]\n",
    "    },\n",
    "    'cat': {\n",
    "        'oof': np.zeros(len(df_train)),\n",
    "        'test': np.zeros(len(df_valid)),\n",
    "        'stage1_models': [None for _ in range(N_FOLD)],\n",
    "        'stage2_models': [None for _ in range(N_FOLD)]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de135a3-8f8c-4e1a-bf07-8b1a4f8b2760",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dict['lgb']['oof'] = np.zeros(len(df_train))\n",
    "preds_dict['lgb']['test'] = np.zeros(len(df_valid))\n",
    "\n",
    "feature_importance_dict = dict(zip(use_cols, [0 for _ in range(len(use_cols))]))\n",
    "\n",
    "skf = KFold(n_splits=N_FOLD, random_state=23228, shuffle=True)\n",
    "fold_i = 0\n",
    "for train_index, test_index in skf.split(df_train):\n",
    "    fold_i += 1\n",
    "    print('Start %s fold' % (fold_i))\n",
    "    _oof, _preds, model = lgb_model(\n",
    "        df_train[use_cols].fillna(-99999).values[train_index,:], \n",
    "        df_train[target_col].values[train_index],\n",
    "        df_train[use_cols].fillna(-99999).values[test_index,:], \n",
    "        df_train[target_col].values[test_index],\n",
    "        df_valid[use_cols].fillna(-99999).values,\n",
    "        [],\n",
    "        use_cols\n",
    "    )\n",
    "    preds_dict['lgb']['oof'][test_index] = _oof\n",
    "    preds_dict['lgb']['test'] += _preds / skf.n_splits\n",
    "    preds_dict['lgb']['stage1_models'][fold_i-1] = model\n",
    "    for feature, importance in zip(model.feature_name(), model.feature_importance()):\n",
    "        feature_importance_dict[feature] += importance\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "feature_importance_df['Feature'] = list(feature_importance_dict.keys())\n",
    "feature_importance_df['Importance'] = list(feature_importance_dict.values())\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "feature_importance_df.head(100).sort_values(by='Importance').plot(kind='barh', x=\"Feature\", y=\"Importance\", figsize=(9,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf94686-ffc3-4815-aecd-f9bced6f7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance_df.to_csv('feature_importance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0600e05-872c-4e5b-8944-35aaa7bd291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mape(df_train['price'].values, preds_dict['lgb']['oof'][:len(df_train)])\n",
    "print(f'{N_FOLD}-Folds CV, LightGBM MAPE = {round(score, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181d10b-2bc6-4542-8f39-3e2b048fcd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dict['xgb']['oof'] = np.zeros(len(df_train))\n",
    "preds_dict['xgb']['test'] = np.zeros(len(df_valid))\n",
    "\n",
    "skf = KFold(n_splits=N_FOLD, random_state=26608, shuffle=True)\n",
    "fold_i = 0\n",
    "for train_index, test_index in skf.split(df_train):\n",
    "    fold_i += 1\n",
    "    print('Start %s fold' % (fold_i))\n",
    "    _oof, _preds, model = xgboost_model(\n",
    "        df_train[use_cols].fillna(-99999).iloc[train_index,:], \n",
    "        df_train[target_col].values[train_index],\n",
    "        df_train[use_cols].fillna(-99999).iloc[test_index,:], \n",
    "        df_train[target_col].values[test_index],\n",
    "        df_valid[use_cols].fillna(-99999),\n",
    "        categorical_feature,\n",
    "        use_cols\n",
    "    )\n",
    "    preds_dict['xgb']['oof'][test_index] = _oof\n",
    "    preds_dict['xgb']['test'] += _preds / skf.n_splits\n",
    "    preds_dict['xgb']['stage1_models'][fold_i-1] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89e58b-f573-4546-8557-337dc7cc02ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mape(df_train['price'].values, preds_dict['xgb']['oof'][:len(df_train)])\n",
    "print(f'{N_FOLD}-Folds CV, XGBoost MAPE = {round(score, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6986765a-1d0d-4212-bc73-6c4dbef3b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dict['cat']['oof'] = np.zeros(len(df_train))\n",
    "preds_dict['cat']['test'] = np.zeros(len(df_valid))\n",
    "\n",
    "skf = KFold(n_splits=N_FOLD, random_state=23228, shuffle=True)\n",
    "fold_i = 0\n",
    "for train_index, test_index in skf.split(df_train):\n",
    "    fold_i += 1\n",
    "    print('Start %s fold' % (fold_i))\n",
    "    _oof, _preds, model = catboost_model(\n",
    "        df_train[use_cols].fillna(-99999).iloc[train_index,:], \n",
    "        df_train[target_col].values[train_index],\n",
    "        df_train[use_cols].fillna(-99999).iloc[test_index,:], \n",
    "        df_train[target_col].values[test_index],\n",
    "        df_valid[use_cols].fillna(-99999),\n",
    "        categorical_feature,\n",
    "        use_cols\n",
    "    )\n",
    "    preds_dict['cat']['oof'][test_index] = _oof\n",
    "    preds_dict['cat']['test'] += _preds / skf.n_splits\n",
    "    preds_dict['cat']['stage1_models'][fold_i-1] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be591cd-eea9-41c1-94b0-b648811b3a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mape(df_train['price'].values, preds_dict['cat']['oof'][:len(df_train)])\n",
    "print(f'{N_FOLD}-Folds CV, CatBoost MAPE = {round(score, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e13c309-f594-40b5-903a-26d37c05e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result['true'] = df_train['price'].values\n",
    "result['lgb_pred'] = preds_dict['lgb']['oof'][:len(df_train)]\n",
    "result['xgb_pred'] = preds_dict['xgb']['oof'][:len(df_train)]\n",
    "result['cat_pred'] = preds_dict['cat']['oof'][:len(df_train)]\n",
    "result.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d27cac-0bcf-40a5-8f11-2abf9c80a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['ensamble_pred'] = result['lgb_pred']*0.33 + result['cat_pred']*0.33 + result['xgb_pred']*0.34\n",
    "score = mape(result['true'].values, result['ensamble_pred'])\n",
    "print(f'{N_FOLD}-Folds CV, Ensemble MAPE = {round(score, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905a93ea-0ea2-4b39-ad1d-ae18f308e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cols = ['ID', 'predicted_price']\n",
    "df_valid['predicted_price'] = preds_dict['cat']['test']*0.34 + preds_dict['lgb']['test']*0.33 + preds_dict['xgb']['test']*0.33\n",
    "#df_valid[save_cols].to_csv(f'../{sub_prefix}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89b9a43-e595-4348-bd21-cc196a9b4c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid[save_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de000a0-1057-4459-938d-f1f22f665793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking\n",
    "df_oof_preds = pd.DataFrame()\n",
    "df_oof_preds['price'] = df_train['price']\n",
    "df_oof_preds['xgb_preds'] = preds_dict['xgb']['oof']\n",
    "df_oof_preds['lgb_preds'] = preds_dict['lgb']['oof']\n",
    "df_oof_preds['cat_preds'] = preds_dict['cat']['oof']\n",
    "\n",
    "df_test_preds = pd.DataFrame()\n",
    "df_test_preds['xgb_preds'] = preds_dict['xgb']['test']\n",
    "df_test_preds['lgb_preds'] = preds_dict['lgb']['test']\n",
    "df_test_preds['cat_preds'] = preds_dict['cat']['test']\n",
    "\n",
    "model = SVR(kernel='linear', C=0.05, max_iter=2000000)\n",
    "stacking_cols = ['lgb_preds', 'xgb_preds', 'cat_preds']\n",
    "x = df_oof_preds[stacking_cols].fillna(0)\n",
    "pred_x = df_test_preds[stacking_cols].fillna(0)\n",
    "y = df_oof_preds['price'].values\n",
    "model.fit(x, y)\n",
    "df_valid['predicted_price2'] = model.predict(pred_x)\n",
    "print(df_valid[['predicted_price', 'predicted_price2']].describe())\n",
    "\n",
    "save_cols = ['ID', 'predicted_price']\n",
    "df_valid['predicted_price'] = df_valid['predicted_price2']\n",
    "#df_valid[save_cols].to_csv(f'../{sub_prefix}_with_svr_stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085a989-9d41-406b-934d-e2186c25c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_hour = (datetime.datetime.now()-start).total_seconds() / 60 / 60\n",
    "print(f'第一階段模型訓練與預測完成，目前花費 {use_hour} 小時')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c50ec-e4b0-42ec-8a54-7e5b5e515548",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_pseudo = df_valid.copy()\n",
    "df_valid_pseudo['price'] = df_valid['predicted_price']\n",
    "df_train_pseudo = pd.concat([df_train, df_valid_pseudo]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9209f2c2-2967-43a5-9901-e4c1799b64b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_pseudo['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645b3c2-db5c-4a21-8527-0afbfb324f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_epochs = 1.1 * sum(preds_dict['cat']['stage1_models'][i].get_best_iteration() for i in range(len(preds_dict['cat']['stage1_models']))) / len(preds_dict['cat']['stage1_models'])\n",
    "xgb_epochs = 1.1 * sum(preds_dict['xgb']['stage1_models'][i].best_iteration for i in range(len(preds_dict['xgb']['stage1_models']))) / len(preds_dict['xgb']['stage1_models'])\n",
    "lgb_epochs = 1.1 * sum(preds_dict['lgb']['stage1_models'][i].best_iteration for i in range(len(preds_dict['lgb']['stage1_models']))) / len(preds_dict['lgb']['stage1_models'])\n",
    "\n",
    "cat_epochs = int(cat_epochs)\n",
    "xgb_epochs = int(xgb_epochs)\n",
    "lgb_epochs = int(lgb_epochs)\n",
    "\n",
    "print(cat_epochs, xgb_epochs, lgb_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd17106-318f-42b9-bf52-b8f20f7503ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_model(x, y, oof_x, oof_y, test_x, categorical_feature, feature_name):\n",
    "    catboost_params = {\n",
    "        'learning_rate': 0.03,\n",
    "        'depth': 8,\n",
    "        'iterations': cat_epochs,\n",
    "        'loss_function': 'RMSE',\n",
    "        'eval_metric': 'MAPE',\n",
    "        'thread_count': 22,\n",
    "        'cat_features': categorical_feature,\n",
    "        'bagging_temperature': 0.95\n",
    "    }\n",
    "\n",
    "    y = np.log(y)\n",
    "    oof_y = np.log(oof_y)\n",
    "    \n",
    "    model = CatBoostRegressor(**catboost_params)\n",
    "    model.fit(x, y, eval_set=(oof_x, oof_y), use_best_model=True, early_stopping_rounds=200, verbose=1000)\n",
    "    \n",
    "    oof = model.predict(oof_x)\n",
    "    preds = model.predict(test_x)\n",
    "    \n",
    "    return np.exp(oof), np.exp(preds), model\n",
    "\n",
    "def xgboost_model(x, y, oof_x, oof_y, test_x, categorical_feature, feature_name):\n",
    "    xgb_params = {\n",
    "        'objective': 'reg:squaredlogerror',\n",
    "        'learning_rate': 0.02,\n",
    "        'max_depth': 7,\n",
    "        'n_estimators': xgb_epochs,\n",
    "        'subsample': 0.88,\n",
    "        'colsample_bytree': 0.55,\n",
    "        'verbosity': 1,\n",
    "        'n_jobs': 22,\n",
    "        'eval_metric': 'mape'\n",
    "    }\n",
    "    \n",
    "    d_train = xgb.DMatrix(x, label=y)\n",
    "    d_valid = xgb.DMatrix(oof_x, label=oof_y)\n",
    "    \n",
    "    model = xgb.train(xgb_params, d_train, num_boost_round=xgb_params['n_estimators'], evals=[(d_valid, 'valid')], early_stopping_rounds=200, feval=None, maximize=False, verbose_eval=1000)\n",
    "    \n",
    "    oof = model.predict(d_valid)\n",
    "    preds = model.predict(xgb.DMatrix(test_x))\n",
    "    \n",
    "    return oof, preds, model\n",
    "\n",
    "def lgb_model(x, y, oof_x, oof_y, test_x, categorical_feature, feature_name):\n",
    "    lgb_params = {\n",
    "        'learning_rate': 0.01,\n",
    "        'application': 'regression',\n",
    "        'max_depth': 8,\n",
    "        'num_leaves': 256,\n",
    "        'feature_fraction': 0.44,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 8,\n",
    "        'verbosity': -1,\n",
    "        'metric': 'mape',\n",
    "        'num_threads': 22,\n",
    "        'num_iterations': lgb_epochs\n",
    "    }\n",
    "    \n",
    "    y = np.log(y)\n",
    "    oof_y = np.log(oof_y)\n",
    "    \n",
    "    callbacks = [lgb.log_evaluation(period=1000), lgb.early_stopping(stopping_rounds=200)]\n",
    "    \n",
    "    d_train = lgb.Dataset(x, label=y)\n",
    "    d_valid = lgb.Dataset(oof_x, label=oof_y)\n",
    "    \n",
    "    model = lgb.train(lgb_params, train_set=d_train, valid_sets=d_valid, callbacks=callbacks, feature_name=feature_name, categorical_feature=categorical_feature)\n",
    "\n",
    "    oof = model.predict(oof_x)\n",
    "    preds = model.predict(test_x)\n",
    "    return np.exp(oof), np.exp(preds), model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f825de8-c56f-4162-9669-a1892568196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dict['lgb']['oof'] = np.zeros(len(df_train_pseudo))\n",
    "preds_dict['lgb']['test'] = np.zeros(len(df_valid))\n",
    "skf = KFold(n_splits=N_FOLD, random_state=23228, shuffle=True)\n",
    "fold_i = 0\n",
    "for train_index, test_index in skf.split(df_train_pseudo):\n",
    "    fold_i += 1\n",
    "    print('Start %s fold' % (fold_i))\n",
    "    _oof, _preds, model = lgb_model(\n",
    "        df_train_pseudo[use_cols].fillna(-99999).values[train_index,:], \n",
    "        df_train_pseudo[target_col].values[train_index],\n",
    "        df_train_pseudo[use_cols].fillna(-99999).values[test_index,:], \n",
    "        df_train_pseudo[target_col].values[test_index],\n",
    "        df_valid[use_cols].fillna(-99999).values,\n",
    "        [],\n",
    "        use_cols\n",
    "    )\n",
    "    preds_dict['lgb']['oof'][test_index] = _oof\n",
    "    preds_dict['lgb']['test'] += _preds / skf.n_splits\n",
    "    preds_dict['lgb']['stage2_models'][fold_i-1] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcc759a-0aa9-4e29-a864-08a2a26adc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mape(df_train['price'].values, preds_dict['lgb']['oof'][:len(df_train)])\n",
    "print(f'{N_FOLD}-Folds CV, LightGBM (with pseudo labels) MAPE = {round(score, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9dcf1a-cf2f-40de-aa80-e0ec9834fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dict['cat']['oof'] = np.zeros(len(df_train_pseudo))\n",
    "preds_dict['cat']['test'] = np.zeros(len(df_valid))\n",
    "\n",
    "skf = KFold(n_splits=N_FOLD, random_state=21994, shuffle=True)\n",
    "fold_i = 0\n",
    "for train_index, test_index in skf.split(df_train_pseudo):\n",
    "    fold_i += 1\n",
    "    print('Start %s fold' % (fold_i))\n",
    "    _oof, _preds, model = catboost_model(\n",
    "        df_train_pseudo[use_cols].fillna(-99999).iloc[train_index,:], \n",
    "        df_train_pseudo[target_col].values[train_index],\n",
    "        df_train_pseudo[use_cols].fillna(-99999).iloc[test_index,:], \n",
    "        df_train_pseudo[target_col].values[test_index],\n",
    "        df_valid[use_cols].fillna(-99999),\n",
    "        categorical_feature,\n",
    "        use_cols\n",
    "    )\n",
    "    preds_dict['cat']['oof'][test_index] = _oof\n",
    "    preds_dict['cat']['test'] += _preds / skf.n_splits\n",
    "    preds_dict['cat']['stage2_models'][fold_i-1] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78622adb-5f84-4318-8be2-00efe9555fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mape(df_train['price'].values, preds_dict['cat']['oof'][:len(df_train)])\n",
    "print(f'{N_FOLD}-Folds CV, CatBoost (with pseudo labels) MAPE = {round(score, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a319804c-a04b-4cc2-a2a4-2ffa3915af19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_dict['xgb']['oof'] = np.zeros(len(df_train_pseudo))\n",
    "preds_dict['xgb']['test'] = np.zeros(len(df_valid))\n",
    "\n",
    "skf = KFold(n_splits=N_FOLD, random_state=26608, shuffle=True)\n",
    "fold_i = 0\n",
    "for train_index, test_index in skf.split(df_train_pseudo):\n",
    "    fold_i += 1\n",
    "    print('Start %s fold' % (fold_i))\n",
    "    _oof, _preds, model = xgboost_model(\n",
    "        df_train_pseudo[use_cols].fillna(-99999).iloc[train_index,:], \n",
    "        df_train_pseudo[target_col].values[train_index],\n",
    "        df_train_pseudo[use_cols].fillna(-99999).iloc[test_index,:], \n",
    "        df_train_pseudo[target_col].values[test_index],\n",
    "        df_valid[use_cols].fillna(-99999),\n",
    "        categorical_feature,\n",
    "        use_cols\n",
    "    )\n",
    "    preds_dict['xgb']['oof'][test_index] = _oof\n",
    "    preds_dict['xgb']['test'] += _preds / skf.n_splits\n",
    "    preds_dict['xgb']['stage2_models'][fold_i-1] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde9f7d-2c86-4160-8bac-2f080dda7814",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mape(df_train['price'].values, preds_dict['xgb']['oof'][:len(df_train)])\n",
    "print(f'{N_FOLD}-Folds CV, XGBoost (with pseudo labels) MAPE = {round(score, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a551936a-8a12-4f20-8636-bafddf899d04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_dict['tabnet']['oof'] = np.zeros(len(df_train_pseudo))\n",
    "preds_dict['tabnet']['test'] = np.zeros(len(df_valid))\n",
    "\n",
    "skf = KFold(n_splits=N_FOLD, random_state=26608, shuffle=True)\n",
    "fold_i = 0\n",
    "for train_index, test_index in skf.split(df_train_pseudo):\n",
    "    fold_i += 1\n",
    "    print('Start %s fold' % (fold_i))\n",
    "    _oof, _preds, model = tabnet_model(\n",
    "        df_train_pseudo[use_cols].fillna(df_train_pseudo[use_cols].mean()).iloc[train_index,:], \n",
    "        df_train_pseudo[target_col].values[train_index],\n",
    "        df_train_pseudo[use_cols].fillna(df_train_pseudo[use_cols].mean()).iloc[test_index,:], \n",
    "        df_train_pseudo[target_col].values[test_index],\n",
    "        df_valid[use_cols].fillna(df_valid[use_cols].mean())\n",
    "    )\n",
    "    preds_dict['tabnet']['oof'][test_index] = _oof\n",
    "    preds_dict['tabnet']['test'] += _preds / skf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b210044b-4093-44d1-8372-5ec98f0f454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mape(df_train['price'].values, preds_dict['tabnet']['oof'][:len(df_train)])\n",
    "print(f'{N_FOLD}-Folds CV, TabNet (with pseudo labels) MAPE = {round(score, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f1a06c-3cb2-445b-9536-16e0a5756015",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_cols = ['nearest_100_price_mean',\n",
    " 'nearest_30_price_mean',\n",
    " 'nearest_10_price_mean',\n",
    " 'city12_price_mean',\n",
    " 'externalkey_price_mean',\n",
    " 'externalkey_samebuilding_price_mean',\n",
    " 'externalkey_samefloor_price_mean',\n",
    " 'externalkey_sameage_price_mean',\n",
    " 'externalkey_sameage_05_price_mean',\n",
    " 'externalkey_sameage_0.25_price_mean',\n",
    " 'externalkey_exactly_same_price_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0701b1e-ee58-4416-8708-1db78a5d0bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dict['knn']['oof'] = np.zeros(len(df_train_pseudo))\n",
    "preds_dict['knn']['test'] = np.zeros(len(df_valid))\n",
    "\n",
    "skf = KFold(n_splits=N_FOLD, random_state=26608, shuffle=True)\n",
    "fold_i = 0\n",
    "for train_index, test_index in skf.split(df_train_pseudo):\n",
    "    fold_i += 1\n",
    "    print('Start %s fold' % (fold_i))\n",
    "    _oof, _preds = knn_model(\n",
    "        df_train_pseudo[prices_cols].fillna(df_train_pseudo[prices_cols].mean()).iloc[train_index,:], \n",
    "        df_train_pseudo[target_col].values[train_index],\n",
    "        df_train_pseudo[prices_cols].fillna(df_train_pseudo[prices_cols].mean()).iloc[test_index,:], \n",
    "        df_train_pseudo[target_col].values[test_index],\n",
    "        df_valid[prices_cols].fillna(df_valid[prices_cols].mean())\n",
    "    )\n",
    "    preds_dict['knn']['oof'][test_index] = _oof\n",
    "    preds_dict['knn']['test'] += _preds / skf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166debb-c055-4b70-9a95-516a8b823d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mape(df_train['price'].values, preds_dict['knn']['oof'][:len(df_train)])\n",
    "print(f'{N_FOLD}-Folds CV, KNN (with pseudo labels) MAPE = {round(score, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a02bbd3-7365-4d19-8c77-b7b1d5438a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result['true'] = df_train['price'].values\n",
    "result['lgb_pred'] = preds_dict['lgb']['oof'][:len(df_train)]\n",
    "result['xgb_pred'] = preds_dict['xgb']['oof'][:len(df_train)]\n",
    "result['cat_pred'] = preds_dict['cat']['oof'][:len(df_train)]\n",
    "result['tabnet_pred'] = preds_dict['tabnet']['oof'][:len(df_train)]\n",
    "result['knn_pred'] = preds_dict['knn']['oof'][:len(df_train)]\n",
    "\n",
    "print(result.describe())\n",
    "print(result.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff13b46-419c-4f77-a852-9d89b1e8a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['ensamble_pred'] = result['lgb_pred']*0.33 + result['cat_pred']*0.33 + result['xgb_pred']*0.34\n",
    "score = mape(result['true'].values, result['ensamble_pred'])\n",
    "print(f'{N_FOLD}-Folds CV, Ensemble (with pseudo labels) MAPE = {round(score, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d91d97-4a4a-47ca-80df-bce2ec396cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cols = ['ID', 'predicted_price']\n",
    "df_valid['predicted_price'] = preds_dict['cat']['test']*0.34 + preds_dict['lgb']['test']*0.33 + preds_dict['xgb']['test']*0.33\n",
    "#df_valid[save_cols].to_csv(f'../{sub_prefix}_pseudo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6882630-e5a6-45ad-a640-1d5813026b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid[save_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d64bd5-804b-4851-8fd5-c69840d4387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking\n",
    "df_oof_preds = pd.DataFrame()\n",
    "df_oof_preds['price'] = df_train['price']\n",
    "df_oof_preds['xgb_preds'] = preds_dict['xgb']['oof'][:len(df_train)]\n",
    "df_oof_preds['lgb_preds'] = preds_dict['lgb']['oof'][:len(df_train)]\n",
    "df_oof_preds['cat_preds'] = preds_dict['cat']['oof'][:len(df_train)]\n",
    "df_oof_preds['tabnet_preds'] = preds_dict['tabnet']['oof'][:len(df_train)]\n",
    "df_oof_preds['knn_preds'] = preds_dict['knn']['oof'][:len(df_train)]\n",
    "\n",
    "df_test_preds = pd.DataFrame()\n",
    "df_test_preds['xgb_preds'] = preds_dict['xgb']['test']\n",
    "df_test_preds['lgb_preds'] = preds_dict['lgb']['test']\n",
    "df_test_preds['cat_preds'] = preds_dict['cat']['test']\n",
    "df_test_preds['tabnet_preds'] = preds_dict['tabnet']['test']\n",
    "df_test_preds['knn_preds'] = preds_dict['knn']['test']\n",
    "\n",
    "model = SVR(kernel='linear', C=0.1, max_iter=2000000)\n",
    "stacking_cols = ['lgb_preds', 'xgb_preds', 'cat_preds', 'tabnet_preds', 'knn_preds']\n",
    "x = df_oof_preds[stacking_cols].fillna(0)\n",
    "pred_x = df_test_preds[stacking_cols].fillna(0)\n",
    "y = df_oof_preds['price'].values\n",
    "model.fit(x, y)\n",
    "df_valid['predicted_price2'] = model.predict(pred_x)\n",
    "print(df_valid[['predicted_price', 'predicted_price2']].describe())\n",
    "\n",
    "save_cols = ['ID', 'predicted_price']\n",
    "df_valid['predicted_price'] = df_valid['predicted_price2']\n",
    "df_valid[save_cols].to_csv(f'../{sub_prefix}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3466298d-7965-4c07-9e4d-9a53e1852700",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_hour = (datetime.datetime.now()-start).total_seconds() / 60 / 60\n",
    "print(f'第二階段預測完成，總花費 {use_hour} 小時')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211640fa-2b10-4c9b-9ca2-2c58189aeacd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
